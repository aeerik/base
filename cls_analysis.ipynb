{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erika\\Desktop\\Exjobb\\repo\\base\n",
      "\n",
      " Retrieving data from: c:\\Users\\erika\\Desktop\\Exjobb\\data\n",
      "Loading data...\n",
      "Data correctly loaded, 6485 samples found\n",
      "Creating vocabulary...\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "#load data\n",
    "# create new dataset which has more information (country, number of genes etc)\n",
    "# run a 1 epoch no batching training\n",
    "# extract the CLS \n",
    "#PCA --> Plotting \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchtext\n",
    "import torchtext.vocab as vocab\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "from data_preprocessing import data_loader, data_original\n",
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "from bert_builder import BERT\n",
    "from misc import get_paths\n",
    "from misc import model_loader\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "############################\n",
    "\n",
    "model_name = '2024-03-14modelEnc3Emb256Mask0.15ModeTrue.pt'\n",
    "hyperparameters = re.findall('[A-Z][^A-Z]*', model_name)\n",
    "numbers = []\n",
    "for i in range (len(hyperparameters)):\n",
    "    numbers.append(re.findall('\\d+', hyperparameters[i]))\n",
    "\n",
    "parameters = [int(num) for sublist in numbers for num in sublist if num]\n",
    "\n",
    "\n",
    "num_enc = parameters[0]\n",
    "dim_emb = parameters[1]\n",
    "dim_hidden = parameters[1]\n",
    "mask_prob = 0\n",
    "\n",
    "########################\n",
    "threshold_year = 1970\n",
    "max_length = [51,44]\n",
    "mask_prob = 0.15\n",
    "drop_prob = 0.2\n",
    "reduced_samples = 1000 \n",
    "\n",
    "dim_emb = 256\n",
    "dim_hidden = 256\n",
    "attention_heads = 4 \n",
    "\n",
    "include_pheno = True   \n",
    "\n",
    "\n",
    "#############################\n",
    "\n",
    "base_dir = Path(os.path.abspath(''))\n",
    "os.chdir(base_dir)\n",
    "data_dir, ab_dir, save_directory = get_paths()\n",
    "\n",
    "print(f\"\\n Retrieving data from: {data_dir}\")\n",
    "print(\"Loading data...\")\n",
    "NCBI,ab_df = data_loader(include_pheno,threshold_year,data_dir,ab_dir)\n",
    "NCBI_geno_only = data_original(threshold_year,data_dir, ab_dir)\n",
    "print(f\"Data correctly loaded, {len(NCBI)} samples found\")\n",
    "print(\"Creating vocabulary...\")\n",
    "vocabulary_geno = vocab_geno(NCBI_geno_only)\n",
    "vocabulary_pheno = vocab_pheno(ab_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "model_name = '2024-03-14modelEnc3Emb256Mask0.15ModeTrue.pt'\n",
    "hyperparameters = re.findall('[A-Z][^A-Z]*', model_name)\n",
    "numbers = []\n",
    "for i in range (len(hyperparameters)):\n",
    "    numbers.append(re.findall('\\d+', hyperparameters[i]))\n",
    "\n",
    "parameters = [int(num) for sublist in numbers for num in sublist if num]\n",
    "\n",
    "\n",
    "num_enc = parameters[0]\n",
    "dim_emb = parameters[1]\n",
    "dim_hidden = parameters[1]\n",
    "print((dim_emb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exjobb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
