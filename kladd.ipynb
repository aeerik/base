{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from itertools import chain \n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import vocab as Vocab\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pathing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lokalt\n",
    "data_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\data'\n",
    "ab_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\repo\\\\base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stationÃ¤r\n",
    "data_dir = 'c:\\\\Users\\\\erikw\\\\Desktop\\\\Exjobb kod\\\\data'\n",
    "ab_dir = 'c:\\\\Users\\\\erikw\\\\Desktop\\\\Exjobb kod\\\\base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saga\n",
    "data_dir = \"/home/aeerik/data/raw/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget config file\n",
    "include_pheno = False\n",
    "threshold_year = 1970\n",
    "data_path = data_dir\n",
    "ab_path = ab_dir\n",
    "max_length = [51,37]\n",
    "mask_prob = 0.15\n",
    "embedding_dim = 32\n",
    "drop_prob = 0.2\n",
    "\n",
    "#Encoder\n",
    "dim_emb = 128\n",
    "dim_hidden = 128\n",
    "attention_heads = 8 \n",
    "\n",
    "#BERT\n",
    "num_encoders = 2\n",
    "\n",
    "#trainer\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "stop_patience = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "include_pheno = False\n",
    "vocabulary = vocab_geno(NCBI, include_pheno)\n",
    "vocab = vocab_pheno(ab_df)\n",
    "print(len(vocabulary))\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "from data_preprocessing import data_loader\n",
    "from create_dataset import NCBIDataset\n",
    "\n",
    "include_pheno = True\n",
    "threshold_year = 1970\n",
    "\n",
    "data_path = data_dir\n",
    "ab_path = ab_dir\n",
    "\n",
    "NCBI,ab_df = data_loader(include_pheno,threshold_year,data_path,ab_path)\n",
    "\n",
    "max_length = [51,37]\n",
    "mask_prob = 0.25\n",
    "vocabulary_geno = vocab_geno(NCBI, include_pheno)\n",
    "vocabulary_pheno = vocab_pheno(ab_df)\n",
    "\n",
    "test_set = NCBIDataset(NCBI, vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "test_set.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = deepcopy(NCBI['AST_phenotypes'].tolist())\n",
    "max_seq_len = [max_length[0],max_length[1]]\n",
    "list_idx = []\n",
    "list_SR = []\n",
    "for i in range(len(sequences)):\n",
    "    current_seq = sequences[i]\n",
    "    current_idxs = []\n",
    "    current_SRs = []\n",
    "    for j in range(len(current_seq)):\n",
    "        item = current_seq[j].split('=')\n",
    "        abs = item[0]   \n",
    "        sr = item[1]\n",
    "        current_idxs.append(vocabulary_pheno.lookup_indices([abs]))\n",
    "        for k in range(len(sr)):\n",
    "            if sr == 'R':\n",
    "                current_SRs.append(1)\n",
    "            else:\n",
    "                current_SRs.append(0)\n",
    "\n",
    "    if len(current_idxs) != len(current_SRs):\n",
    "        print(\"current sequence:\",current_seq, \"\\n\", \"with length:\", len(current_seq))\n",
    "        print(\"indexes:\",current_idxs, \"with length:\", len(current_idxs))\n",
    "        print(\"suceptability\",current_SRs, \"with length:\", len(current_SRs))\n",
    "        print('error at', j)\n",
    "        print(\"--------------------\")\n",
    "    current_idxs = [int(item[0]) for item in current_idxs]\n",
    "    #for i in range(0,max_length[1] - len(current_idxs)):\n",
    "    #    current_idxs.append(-1)\n",
    "    #for i in range(0,max_length[1] - len(current_SRs)):\n",
    "    #    current_SRs.append(-1)\n",
    "    list_idx.append(current_idxs)\n",
    "    list_SR.append(current_SRs)\n",
    "for i in range(len(list_idx)):\n",
    "    if len(list_idx[i]) != len(list_SR[i]):\n",
    "        print('error at', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from bert_builder import BERT_ft\n",
    "\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "for i, batch in enumerate(loader):\n",
    "    if i >= 5:\n",
    "        break \n",
    "    input, token_target, attn_mask, AB_idx, SR_class  = batch\n",
    "    bert_test = BERT_ft(vocab_size=len(vocabulary_geno), max_length=51, dim_embedding = 128, dim_hidden= 128, attention_heads=8, num_encoders=2, dropout_prob=0.2, num_ab=81, device=device)\n",
    "    token_pred, res_pred = bert_test.forward(input, attn_mask)\n",
    "    res_pred = torch.where(res_pred > 0, torch.ones_like(res_pred), torch.zeros_like(res_pred))\n",
    "    list_AB_predictions = []\n",
    "    for i, row in enumerate(res_pred):\n",
    "        AB_list = 0\n",
    "        AB_list = [elem.item() for elem in AB_idx[i] if elem.item() != -1]\n",
    "        current_abs = []\n",
    "        for ab in AB_list:\n",
    "            current_abs.append(row[ab].item())\n",
    "        current_abs = torch.tensor(current_abs)\n",
    "        current_abs = current_abs.type(torch.int16)\n",
    "        list_AB_predictions.append(current_abs)\n",
    "    \n",
    "        processed_tensor = [row[row != -1] for row in SR_class]\n",
    "    for i, row in enumerate(processed_tensor):\n",
    "        correct = (row == list_AB_predictions[i]).sum().item()\n",
    "        print(correct)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = res_pred[14]\n",
    "print(test)\n",
    "pred_res = torch.where(test > 0, torch.ones_like(test), torch.zeros_like(test))\n",
    "print(pred_res)\n",
    "indicies = [1,2,3,4]\n",
    "test = pred_res[indicies]\n",
    "print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from create_dataset import NCBIDataset\n",
    "def get_split_indices(size_to_split, val_share, random_state: int = 42):\n",
    "    indices = np.arange(size_to_split)\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_share = 1 - val_share\n",
    "    \n",
    "    train_size = int(train_share * size_to_split)\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "    \n",
    "    return train_indices, val_indices\n",
    "max_length = 20\n",
    "mask_prob = 0.30\n",
    "vocabulary = make_vocabulary(NCBI)\n",
    "\n",
    "train_indices, val_indices = get_split_indices(len(NCBI), 0.2)\n",
    "train_set = NCBIDataset(NCBI.iloc[train_indices], vocabulary, max_length, mask_prob)\n",
    "val_set = NCBIDataset(NCBI.iloc[val_indices], vocabulary, max_length, mask_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n",
    "class BertTrainer_ft:\n",
    "    def __init__(self, model, train_set, val_set, epochs, batch_size, lr, device, stop_patience, wandb_mode, project_name, wandb_name):\n",
    "        \n",
    "        self.model = model\n",
    "        self.train_set = train_set\n",
    "        self.train_size = len(train_set)\n",
    "        self.val_set = val_set\n",
    "        self.epochs = epochs    \n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = self.train_size // self.batch_size\n",
    "        self.lr = lr\n",
    "        self.weight_decay = 0.01\n",
    "        self.current_epoch  = 0\n",
    "        self.early_stopping_counter = 0\t\n",
    "        self.patience = stop_patience\n",
    "        \n",
    "        self.wandb_mode = wandb_mode\n",
    "        self.project_name = project_name\n",
    "        self.wandb_name = wandb_name\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        self.token_criterion = nn.CrossEntropyLoss(ignore_index = -1).to(device)\n",
    "        self.ab_criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def __call__(self):   \n",
    "        if self.wandb_mode:\n",
    "            self._init_wandb()   \n",
    "        self.val_set.prepare_dataset() \n",
    "        self.val_loader = DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False)\n",
    "        start_time = time.time()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self._init_result_lists()\n",
    "        for self.current_epoch in range(self.current_epoch, self.epochs):\n",
    "            #Training\n",
    "            self.model.train()\n",
    "            self.train_set.prepare_dataset()\n",
    "            self.train_loader = DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
    "            epoch_start_time = time.time()\n",
    "            avg_epoch_loss_total, avg_epoch_loss_geno, avg_epoch_loss_ab = self.train(self.current_epoch)\n",
    "            self.train_losses_total.append(avg_epoch_loss_total)\n",
    "            self.train_losses_geno.append(avg_epoch_loss_geno) \n",
    "            self.train_losses_ab.append(avg_epoch_loss_ab)  \n",
    "            print(f\"Epoch completed in {(time.time() - epoch_start_time)/60:.1f} min\")\n",
    "            \n",
    "            #Validation\n",
    "            print(\"Evaluating on validation set...\")\n",
    "            val_results = self.evaluate(self.val_loader)\n",
    "            print(f\"Elapsed time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))}\")\n",
    "            self.val_losses_total.append(val_results[0])  \n",
    "            self.val_losses_geno.append(val_results[1])\n",
    "            self.val_losses_ab.append(val_results[2])\n",
    "            self.val_accs.append(val_results[3])\n",
    "            if self.wandb_mode:\n",
    "                self._report_epoch_results()\n",
    "            criterion = self.stop_early()\n",
    "            if criterion:\n",
    "                print(f\"Training interrupted at epoch: {self.current_epoch+1}\")\n",
    "                break\n",
    "        print(f\"-=Training completed=-\")\n",
    "        results = {\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "            \"total_train_losses\": self.train_losses_total,\n",
    "            \"geno_train_losses\": self.train_losses_geno,\n",
    "            \"ab_train_losses\": self.train_losses_ab,\n",
    "            \"total_val_losses\": self.val_losses_total,\n",
    "            \"geno_val_losses\": self.val_losses_geno,\n",
    "            \"ab_val_losses\": self.val_losses_ab,\n",
    "            \"val_accs\": self.val_accs\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    def _init_result_lists(self):\n",
    "\n",
    "        self.train_losses_total = []\n",
    "        self.train_losses_geno = []\n",
    "        self.train_losses_ab = []\n",
    "\n",
    "        self.val_losses_total = []\n",
    "        self.val_losses_geno = []\n",
    "        self.val_losses_ab = []\n",
    "\n",
    "        self.val_accs = []\n",
    "    \n",
    "    def stop_early(self):\n",
    "        if self.val_losses_total[-1] < self.best_val_loss:\n",
    "            self.best_val_loss = self.val_losses_total[-1]\n",
    "            self.best_epoch = self.current_epoch\n",
    "            self.best_model_state = self.model.state_dict()\n",
    "            self.early_stopping_counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "            return True if self.early_stopping_counter >= self.patience else False\n",
    "\n",
    "    def train(self, epoch: int):\n",
    "        print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "        time_ref = time.time()\n",
    "        \n",
    "        epoch_loss_total = 0\n",
    "        epoch_loss_geno = 0\n",
    "        epoch_loss_ab = 0\n",
    "\n",
    "        for i, batch in enumerate(self.train_loader):\n",
    "            input, token_target, attn_mask, AB_idx, SR_class = batch\n",
    "            ABinclusion = torch.unique(AB_idx)\n",
    "            ABinclusion = ABinclusion[ABinclusion != -1]\n",
    "            ABinclusion = ABinclusion.tolist()\n",
    "            self.model.exclude_networks(ABinclusion)\n",
    "\n",
    "            self.optimizer.zero_grad() \n",
    "\n",
    "            token_predictions, resistance_predictions = self.model(input, attn_mask) \n",
    "            geno_loss = self.token_criterion(token_predictions.transpose(-1, -2), token_target) \n",
    "            print(\"geno_loss\", geno_loss)\n",
    "            print(\"type geno\",type(geno_loss))\n",
    "            print(\"----------\")\n",
    "            list_AB_predictions = []\n",
    "            for i, row in enumerate(resistance_predictions):\n",
    "                AB_list = 0\n",
    "                AB_list = [elem.item() for elem in AB_idx[i] if elem.item() != -1]\n",
    "                current_abs = []\n",
    "                for ab in AB_list:\n",
    "                    current_abs.append(row[ab].item())\n",
    "                current_abs = torch.tensor(current_abs)\n",
    "                list_AB_predictions.append(current_abs)\n",
    "            \n",
    "            processed_tensor = [row[row != -1] for row in SR_class]\n",
    "            for i, row in enumerate(processed_tensor):\n",
    "                row = row.type(torch.float32)\n",
    "                ab_loss =+ self.ab_criterion(list_AB_predictions[i], row)\n",
    "            print(\"ab_loss\", ab_loss)\n",
    "            print(\"type ab\",type(ab_loss))  \n",
    "            print(\"-----------\")\n",
    "            \n",
    "            total_loss = geno_loss + ab_loss\n",
    "            epoch_loss_total += total_loss.item() \n",
    "            epoch_loss_geno += geno_loss.item()\n",
    "            epoch_loss_ab += ab_loss.item()\n",
    "            \n",
    "            initial_params = {}\n",
    "            for name, param in self.model.named_parameters():\n",
    "                initial_params[name] = copy.deepcopy(param.data.clone())\n",
    "            \n",
    "            print(\"total loss\",total_loss)\n",
    "            print(\"type:\",type(total_loss))\n",
    "            total_loss.backward() \n",
    "            self.optimizer.step()\n",
    "            self.model.reset_exclusion()   \n",
    "            updated_params = {}\n",
    "            for name, param in self.model.named_parameters():    \n",
    "                updated_params[name] = copy.deepcopy(param.data.clone())\n",
    "            parameters_updated = False\n",
    "            for name in initial_params:\n",
    "                if not torch.allclose(initial_params[name], updated_params[name]):\n",
    "                    parameters_updated = True\n",
    "                break\n",
    "            if parameters_updated:\n",
    "                print(\"Parameters have been updated.\")\n",
    "            else:\n",
    "                print(\"Parameters have not been updated.\")\n",
    "              \n",
    "        avg_epoch_loss_total = epoch_loss_total / self.num_batches\n",
    "        avg_epoch_loss_geno = epoch_loss_geno / self.num_batches\n",
    "        avg_epoch_loss_ab = epoch_loss_ab / self.num_batches\n",
    "\n",
    "        return avg_epoch_loss_total, avg_epoch_loss_geno, avg_epoch_loss_ab\n",
    "    \n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        epoch_loss_total = 0\n",
    "        epoch_loss_geno = 0\n",
    "        epoch_loss_ab = 0\n",
    "        total_correct = 0\n",
    "        total_sum = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(loader):\n",
    "                input, token_target, attn_mask, AB_idx, SR_class = batch\n",
    "\n",
    "                token_predictions, resistance_predictions = self.model(input, attn_mask) \n",
    "                geno_loss = self.token_criterion(token_predictions.transpose(-1, -2), token_target) \n",
    "                \n",
    "                list_AB_predictions = []\n",
    "                for i, row in enumerate(resistance_predictions):\n",
    "                    AB_list = 0\n",
    "                    AB_list = [elem.item() for elem in AB_idx[i] if elem.item() != -1]\n",
    "                    current_abs = []\n",
    "                    for ab in AB_list:\n",
    "                        current_abs.append(row[ab].item())\n",
    "                    current_abs = torch.tensor(current_abs)\n",
    "                    list_AB_predictions.append(current_abs)\n",
    "                \n",
    "                processed_tensor = [row[row != -1] for row in SR_class]\n",
    "                for i, row in enumerate(processed_tensor):\n",
    "                    row = row.type(torch.float32)\n",
    "                    ab_loss =+ self.ab_criterion(list_AB_predictions[i], row)\n",
    "                \n",
    "                avg_total_loss = geno_loss.item() + ab_loss.item()\n",
    "                epoch_loss_total += avg_total_loss \n",
    "                epoch_loss_geno += geno_loss.item()\n",
    "                epoch_loss_ab += ab_loss.item() \n",
    "                \n",
    "                list_AB_predictions = []\n",
    "                for i, row in enumerate(resistance_predictions):\n",
    "                    AB_list = 0\n",
    "                    AB_list = [elem.item() for elem in AB_idx[i] if elem.item() != -1]\n",
    "                    current_abs = []\n",
    "                    for ab in AB_list:\n",
    "                        current_abs.append(row[ab].item())\n",
    "                    current_abs = torch.tensor(current_abs)\n",
    "                    current_abs = current_abs.type(torch.int16)\n",
    "                    list_AB_predictions.append(current_abs)\n",
    "                \n",
    "                    processed_tensor = [row[row != -1] for row in SR_class]\n",
    "                for i, row in enumerate(processed_tensor):\n",
    "                    total_correct += (row == list_AB_predictions[i]).sum().item()\n",
    "                    total_sum += len(row)\n",
    "\n",
    "        avg_epoch_loss_total = epoch_loss_total / self.num_batches\n",
    "        avg_epoch_loss_geno = epoch_loss_geno / self.num_batches\n",
    "        avg_epoch_loss_ab = epoch_loss_ab / self.num_batches\n",
    "\n",
    "        accuracy = total_correct / total_sum\n",
    "\n",
    "        return avg_epoch_loss_total, avg_epoch_loss_geno, avg_epoch_loss_ab, accuracy\n",
    "    \n",
    "    def _save_model(self, savepath: Path):\n",
    "        torch.save(self.best_model_state, savepath)\n",
    "        print(f\"Model saved to {savepath}\")\n",
    "        \n",
    "        \n",
    "    def _load_model(self, savepath: Path):\n",
    "        print(f\"Loading model from {savepath}\")\n",
    "        self.model.load_state_dict(torch.load(savepath))\n",
    "        print(\"Model loaded\")\n",
    "\n",
    "    def _init_wandb(self):\n",
    "        self.wandb_run = wandb.init(\n",
    "            project=self.project_name, # name of the project\n",
    "            name=self.wandb_name, # name of the run\n",
    "            \n",
    "            config={\n",
    "                \"epochs\": self.epochs,\n",
    "                \"batch_size\": self.batch_size,\n",
    "                \"num_heads\": self.model.attention_heads,\n",
    "                \"num_encoders\": self.model.num_encoders,\n",
    "                \"emb_dim\": self.model.dim_embedding,\n",
    "                'ff_dim': self.model.dim_embedding,\n",
    "                \"lr\": self.lr,\n",
    "                \"weight_decay\": self.weight_decay,\n",
    "                \"max_seq_len\": self.model.max_length[0],\n",
    "                \"vocab_size\": len(self.train_set.vocab_geno),\n",
    "                \"num_parameters\": sum(p.numel() for p in self.model.parameters() if p.requires_grad),\n",
    "            }\n",
    "        )\n",
    "        self.wandb_run.watch(self.model) # watch the model for gradients and parameters\n",
    "        self.wandb_run.define_metric(\"epoch\", hidden=True)\n",
    "        self.wandb_run.define_metric(\"batch\", hidden=True)\n",
    "\n",
    "        self.wandb_run.define_metric(\"TotalLosses/total_train_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        self.wandb_run.define_metric(\"TotalLosses/total_val_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "\n",
    "        self.wandb_run.define_metric(\"GenoLosses/geno_train_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        self.wandb_run.define_metric(\"GenoLosses/geno_val_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "\n",
    "        self.wandb_run.define_metric(\"AB_Losses/ab_train_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        self.wandb_run.define_metric(\"AB_Losses/ab_val_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "\n",
    "        self.wandb_run.define_metric(\"Accuracies/val_acc\", summary=\"min\", step_metric=\"epoch\")\n",
    "        \n",
    "        self.wandb_run.define_metric(\"Losses/final_val_loss\")\n",
    "        self.wandb_run.define_metric(\"Accuracies/final_val_acc\")\n",
    "        self.wandb_run.define_metric(\"final_epoch\")\n",
    "\n",
    "        return self.wandb_run\n",
    "    \n",
    "    def _report_epoch_results(self):\n",
    "        wandb_dict = {\n",
    "            \"epoch\": self.current_epoch+1,\n",
    "            \"TotalLosses/total_train_loss\": self.train_losses_total[-1],\n",
    "            \"GenoLosses/geno_train_loss\": self.train_losses_geno[-1],\n",
    "            \"ABLosses/ab_train_loss\": self.train_losses_ab[-1],\n",
    "\n",
    "            \"TotalLosses/total_val_loss\": self.val_losses_total[-1],\n",
    "            \"GenoLosses/geno_val_loss\": self.val_losses_geno[-1],\n",
    "            \"ABLosses/ab_val_loss\": self.val_losses_ab[-1],\n",
    "            \n",
    "            \"Accuracies/val_acc\": self.val_accs[-1],\n",
    "        }\n",
    "        self.wandb_run.log(wandb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import data_loader\n",
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "from misc import get_split_indices\n",
    "from create_dataset import NCBIDataset\n",
    "include_pheno = False\n",
    "\n",
    "NCBI,ab_df = data_loader(include_pheno,threshold_year,data_path,ab_path)\n",
    "\n",
    "\n",
    "include_pheno = False\n",
    "max_length = [51,37]\n",
    "mask_prob = 0.25\n",
    "vocabulary_geno = vocab_geno(NCBI, include_pheno)\n",
    "vocabulary_pheno = vocab_pheno(ab_df)\n",
    "\n",
    "test_set = NCBIDataset(NCBI, vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "test_set.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_builder import BERT_pt\n",
    "from trainer import BertTrainer_pt\n",
    "\n",
    "train_indices, val_indices = get_split_indices(len(NCBI), 0.2)\n",
    "train_set = NCBIDataset(NCBI.iloc[train_indices], vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "val_set = NCBIDataset(NCBI.iloc[val_indices], vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BERT_pt(vocab_size=len(vocabulary_geno), max_length=51, dim_embedding = 128, attention_heads=8, num_encoders=2, dropout_prob=0.2)\n",
    "save_directory = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\savefiles'\n",
    "\n",
    "trainer = BertTrainer_pt(model, train_set, val_set, epochs, batch_size, lr, device, stop_patience, save_directory)\n",
    "trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, 1000 samples found\n",
      "length  of token vocabulary: 472\n",
      "Epoch 1/5\n",
      "geno_loss tensor(6.1838, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7814)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.9652, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(6.2208, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8281)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(7.0489, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(6.0512, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7009)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.7522, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(6.0081, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7648)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.7729, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(6.0215, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7553)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.7768, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.7706, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7017)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.4723, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.7107, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.9838)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.6945, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.5007, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7068)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.2075, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.4921, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8369)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.3290, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.7438, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7475)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.4912, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.6352, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6920)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.3271, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2836, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6880)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.9716, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.6100, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8069)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.4169, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.4247, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7948)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.2195, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.5520, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7544)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.3064, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3007, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7240)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0248, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.4163, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7485)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.1648, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3600, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7547)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.1147, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.4208, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(1.0025)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.4234, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.6275, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8221)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.4495, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3531, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7929)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.1460, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3800, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8163)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.1962, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3449, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7822)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.1271, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2909, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8446)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.1355, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.1618, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.4899)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6517, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:06\n",
      "Epoch 2/5\n",
      "geno_loss tensor(5.3426, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7367)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0793, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3048, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8249)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.1298, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2512, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6926)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.9437, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9044, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7070)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6114, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3540, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7314)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0853, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3314, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7171)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0485, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9933, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8094)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.8027, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2241, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8213)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0455, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.3513, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8099)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.1612, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.1834, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6028)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.7862, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2057, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7677)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.9733, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.0779, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7586)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.8364, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.1478, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7369)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.8847, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2025, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7873)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.9898, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.8192, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7533)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.5725, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2338, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7709)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0048, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2670, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7602)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0273, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.1137, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.9158)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0295, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.8441, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7718)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6159, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.0822, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8153)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.8975, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.2900, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6936)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.9836, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.0578, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7946)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.8524, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.0998, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6843)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.7841, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.0776, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7557)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.8332, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.1987, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8865)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(6.0853, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:13\n",
      "Epoch 3/5\n",
      "geno_loss tensor(4.6684, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7119)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3802, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7867, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7384)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.5251, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.8965, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7974)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6939, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9501, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7344)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6845, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9185, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8228)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.7413, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9860, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7455)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.7315, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.6602, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7532)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4135, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9667, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8012)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.7679, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5967, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6999)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.2966, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7611, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7608)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.5219, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9345, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7402)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6748, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.8375, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7833)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6208, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9031, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8328)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.7359, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.8772, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8083)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6855, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.0211, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8239)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.8450, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5691, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.9899)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.5590, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9328, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7252)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6580, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9167, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7309)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6476, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.3489, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.5425)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.8914, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7261, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7135)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4396, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7427, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7481)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4909, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7752, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.9241)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.6994, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5698, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8413)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4111, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.9301, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8404)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.7705, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4355, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6733)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.1088, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:19\n",
      "Epoch 4/5\n",
      "geno_loss tensor(4.5743, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7762)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3506, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.8477, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6676)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.5153, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.1383, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7683)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.9066, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(5.0780, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7969)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.8749, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7104, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7385)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4489, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5501, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7815)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3315, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.0820, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7645)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.8466, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.3837, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6794)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.0630, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.1912, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7755)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.9667, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5674, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7846)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3520, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7011, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7330)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4341, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4766, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8160)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.2926, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7518, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7607)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.5126, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4318, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7096)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.1414, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5265, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6977)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.2242, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5582, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.9575)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.5157, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4791, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7536)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.2327, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.7061, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7543)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4603, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.6597, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7745)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4342, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4106, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6858)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.0964, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.3928, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7547)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.1475, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.3757, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.3869)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.7626, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(3.6509, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7184)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.3692, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5722, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7701)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3423, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4509, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.9062)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3571, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:26\n",
      "Epoch 5/5\n",
      "geno_loss tensor(4.5382, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7319)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.2701, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5989, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7246)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3235, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4485, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6365)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.0850, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.6775, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7986)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4761, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5968, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6970)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.2939, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5178, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8828)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4006, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.2936, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8227)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.1162, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4802, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7797)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.2599, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.2759, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6843)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.9603, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.3285, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7904)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.1189, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5877, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6655)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.2533, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.3088, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6686)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.9774, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.2122, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7035)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.9157, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.6280, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7798)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.4078, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4346, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7386)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.1733, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.2218, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.9025)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.1243, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.5853, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7777)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3631, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4888, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8257)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3145, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.2001, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7883)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.9884, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4782, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8471)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.3253, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.2510, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7613)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.0123, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.2801, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.7290)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.0091, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.1480, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8510)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.9990, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.4307, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.6949)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(5.1256, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "geno_loss tensor(4.1677, grad_fn=<NllLoss2DBackward0>)\n",
      "type geno <class 'torch.Tensor'>\n",
      "----------\n",
      "ab_loss tensor(0.8125)\n",
      "type ab <class 'torch.Tensor'>\n",
      "-----------\n",
      "total loss tensor(4.9802, grad_fn=<AddBackward0>)\n",
      "type: <class 'torch.Tensor'>\n",
      "Parameters have been updated.\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:33\n",
      "-=Training completed=-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 4,\n",
       " 'total_train_losses': [6.367428607940674,\n",
       "  5.922556781768799,\n",
       "  5.559784431457519,\n",
       "  5.279164752960205,\n",
       "  5.170948467254639],\n",
       " 'geno_train_losses': [5.594593563079834,\n",
       "  5.158326988220215,\n",
       "  4.788460216522217,\n",
       "  4.5306782722473145,\n",
       "  4.407156505584717],\n",
       " 'ab_train_losses': [0.7728350567817688,\n",
       "  0.7642298078536988,\n",
       "  0.7713242363929749,\n",
       "  0.7484864401817322,\n",
       "  0.763791983127594],\n",
       " 'total_val_losses': [1.6757190823554993,\n",
       "  1.585795123577118,\n",
       "  1.5216752409934997,\n",
       "  1.4672028088569642,\n",
       "  1.418721957206726],\n",
       " 'geno_val_losses': [1.4653099250793458,\n",
       "  1.3773448371887207,\n",
       "  1.3128943634033203,\n",
       "  1.2616438484191894,\n",
       "  1.2131160068511964],\n",
       " 'ab_val_losses': [0.21040915727615356,\n",
       "  0.20845028638839722,\n",
       "  0.20878087759017944,\n",
       "  0.20555896043777466,\n",
       "  0.20560595035552978],\n",
       " 'val_accs': [0.6396363636363637,\n",
       "  0.644,\n",
       "  0.6425454545454545,\n",
       "  0.6407272727272727,\n",
       "  0.6392727272727273]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_builder import BERT_ft\n",
    "from data_preprocessing import data_loader\n",
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "from misc import get_split_indices\n",
    "from create_dataset import NCBIDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lr = 0.0001\n",
    "\n",
    "include_pheno = True\n",
    "\n",
    "NCBI,ab_df = data_loader(include_pheno,threshold_year,data_path,ab_path)\n",
    "vocabulary_geno = vocab_geno(NCBI, include_pheno)\n",
    "vocabulary_pheno = vocab_pheno(ab_df)\n",
    "\n",
    "reduced_samples = 1000\n",
    "NCBI = NCBI.head(reduced_samples)\n",
    "\n",
    "print(f\"Data loaded, {len(NCBI)} samples found\")\n",
    "print(f\"length  of token vocabulary:\",len(vocabulary_geno))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_indices, val_indices = get_split_indices(len(NCBI), 0.2)\n",
    "train_set = NCBIDataset(NCBI.iloc[train_indices], vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "val_set = NCBIDataset(NCBI.iloc[val_indices], vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "\n",
    "bert_test = BERT_ft(len(vocabulary_geno), max_length, dim_emb, dim_hidden, attention_heads, num_encoders, drop_prob, len(vocabulary_pheno), device)\n",
    "\n",
    "test = BertTrainer_ft(bert_test, train_set, val_set, epochs, batch_size, lr, device, stop_patience, False, \"NCBI\", \"test\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
