{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from itertools import chain \n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import vocab as Vocab\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pathing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lokalt\n",
    "data_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\data'\n",
    "ab_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\repo\\\\base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stationÃ¤r\n",
    "data_dir = 'c:\\\\Users\\\\erikw\\\\Desktop\\\\Exjobb kod\\\\data'\n",
    "ab_dir = 'c:\\\\Users\\\\erikw\\\\Desktop\\\\Exjobb kod\\\\base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saga\n",
    "data_dir = \"/home/aeerik/data/raw/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget config file\n",
    "include_pheno = False\n",
    "threshold_year = 1970\n",
    "data_path = data_dir\n",
    "ab_path = ab_dir\n",
    "max_length = [51,81]\n",
    "mask_prob = 0.15\n",
    "embedding_dim = 32\n",
    "drop_prob = 0.2\n",
    "\n",
    "#Encoder\n",
    "dim_emb = 128\n",
    "dim_hidden = 128\n",
    "attention_heads = 8 \n",
    "\n",
    "#BERT\n",
    "num_encoders = 2\n",
    "\n",
    "#trainer\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "stop_patience = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "include_pheno = False\n",
    "vocabulary = vocab_geno(NCBI, include_pheno)\n",
    "vocab = vocab_pheno(ab_df)\n",
    "print(len(vocabulary))\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "from data_preprocessing import data_loader\n",
    "from create_dataset import NCBIDataset\n",
    "\n",
    "include_pheno = True\n",
    "threshold_year = 1970\n",
    "\n",
    "data_path = data_dir\n",
    "ab_path = ab_dir\n",
    "\n",
    "NCBI,ab_df = data_loader(include_pheno,threshold_year,data_path,ab_path)\n",
    "\n",
    "max_length = [51,81]\n",
    "mask_prob = 0.25\n",
    "vocabulary_geno = vocab_geno(NCBI, include_pheno)\n",
    "vocabulary_pheno = vocab_pheno(ab_df)\n",
    "\n",
    "test_set = NCBIDataset(NCBI, vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "test_set.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = deepcopy(NCBI['AST_phenotypes'].tolist())\n",
    "max_seq_len = [max_length[0],max_length[1]]\n",
    "list_idx = []\n",
    "list_SR = []\n",
    "for i in range(len(sequences)):\n",
    "    current_seq = sequences[i]\n",
    "    current_idxs = []\n",
    "    current_SRs = []\n",
    "    for j in range(len(current_seq)):\n",
    "        item = current_seq[j].split('=')\n",
    "        abs = item[0]   \n",
    "        sr = item[1]\n",
    "        current_idxs.append(vocabulary_pheno.lookup_indices([abs]))\n",
    "        for k in range(len(sr)):\n",
    "            if sr == 'R':\n",
    "                current_SRs.append(1)\n",
    "            else:\n",
    "                current_SRs.append(0)\n",
    "\n",
    "    if len(current_idxs) != len(current_SRs):\n",
    "        print(\"current sequence:\",current_seq, \"\\n\", \"with length:\", len(current_seq))\n",
    "        print(\"indexes:\",current_idxs, \"with length:\", len(current_idxs))\n",
    "        print(\"suceptability\",current_SRs, \"with length:\", len(current_SRs))\n",
    "        print('error at', j)\n",
    "        print(\"--------------------\")\n",
    "    current_idxs = [int(item[0]) for item in current_idxs]\n",
    "    #for i in range(0,max_length[1] - len(current_idxs)):\n",
    "    #    current_idxs.append(-1)\n",
    "    #for i in range(0,max_length[1] - len(current_SRs)):\n",
    "    #    current_SRs.append(-1)\n",
    "    list_idx.append(current_idxs)\n",
    "    list_SR.append(current_SRs)\n",
    "for i in range(len(list_idx)):\n",
    "    if len(list_idx[i]) != len(list_SR[i]):\n",
    "        print('error at', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def custom_loss(logits, targets, pad_index=-1):\n",
    "    #print(logits)\n",
    "    #print(targets)\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "    #print(loss)\n",
    "    mask = (targets != pad_index).float()\n",
    "    #print(mask)\n",
    "    masked_loss = loss * mask\n",
    "    #print(masked_loss)\n",
    "    average_loss = masked_loss.sum() / mask.sum()\n",
    "    #print(average_loss)\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "tensor([0], dtype=torch.int16)\n",
      "0\n",
      "tensor([1])\n",
      "tensor([0], dtype=torch.int16)\n",
      "0\n",
      "tensor([0])\n",
      "tensor([0], dtype=torch.int16)\n",
      "1\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       dtype=torch.int16)\n",
      "13\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1], dtype=torch.int16)\n",
      "27\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1], dtype=torch.int16)\n",
      "35\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int16)\n",
      "41\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], dtype=torch.int16)\n",
      "49\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1], dtype=torch.int16)\n",
      "56\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int16)\n",
      "61\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1], dtype=torch.int16)\n",
      "65\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1], dtype=torch.int16)\n",
      "72\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1])\n",
      "tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1], dtype=torch.int16)\n",
      "77\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1], dtype=torch.int16)\n",
      "82\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1], dtype=torch.int16)\n",
      "90\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int16)\n",
      "98\n",
      "0.45161290322580644\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0], dtype=torch.int16)\n",
      "10\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "21\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0], dtype=torch.int16)\n",
      "27\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "36\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "47\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "60\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "72\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1], dtype=torch.int16)\n",
      "80\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0], dtype=torch.int16)\n",
      "88\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "99\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "112\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "125\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int16)\n",
      "135\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "145\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0], dtype=torch.int16)\n",
      "158\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0])\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1], dtype=torch.int16)\n",
      "167\n",
      "0.6958333333333333\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1], dtype=torch.int16)\n",
      "6\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "18\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "29\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "39\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "51\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0], dtype=torch.int16)\n",
      "62\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "71\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0], dtype=torch.int16)\n",
      "84\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "97\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0], dtype=torch.int16)\n",
      "111\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0], dtype=torch.int16)\n",
      "123\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "136\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0], dtype=torch.int16)\n",
      "149\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "160\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "171\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1], dtype=torch.int16)\n",
      "178\n",
      "0.7416666666666667\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "13\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "24\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "37\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "49\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0], dtype=torch.int16)\n",
      "59\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0], dtype=torch.int16)\n",
      "71\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "84\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0], dtype=torch.int16)\n",
      "95\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0], dtype=torch.int16)\n",
      "106\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "119\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0], dtype=torch.int16)\n",
      "127\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "138\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "150\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0], dtype=torch.int16)\n",
      "160\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "171\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "179\n",
      "0.7458333333333333\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "13\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "26\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "37\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "50\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "65\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "80\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1], dtype=torch.int16)\n",
      "90\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "104\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "118\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "130\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0], dtype=torch.int16)\n",
      "142\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "156\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "171\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "184\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "199\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "210\n",
      "0.875\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "11\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1], dtype=torch.int16)\n",
      "18\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1], dtype=torch.int16)\n",
      "27\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1])\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1], dtype=torch.int16)\n",
      "37\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "46\n",
      "tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1], dtype=torch.int16)\n",
      "55\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1], dtype=torch.int16)\n",
      "64\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "69\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0], dtype=torch.int16)\n",
      "73\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "78\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "81\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "87\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "93\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "97\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0], dtype=torch.int16)\n",
      "102\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1], dtype=torch.int16)\n",
      "107\n",
      "0.4083969465648855\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0])\n",
      "tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1], dtype=torch.int16)\n",
      "7\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1], dtype=torch.int16)\n",
      "13\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0], dtype=torch.int16)\n",
      "19\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "28\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "33\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1], dtype=torch.int16)\n",
      "43\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0], dtype=torch.int16)\n",
      "52\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "58\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "67\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "75\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0], dtype=torch.int16)\n",
      "86\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1], dtype=torch.int16)\n",
      "95\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0], dtype=torch.int16)\n",
      "105\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "113\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0], dtype=torch.int16)\n",
      "117\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], dtype=torch.int16)\n",
      "124\n",
      "0.48627450980392156\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "9\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0], dtype=torch.int16)\n",
      "21\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "33\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1], dtype=torch.int16)\n",
      "41\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1], dtype=torch.int16)\n",
      "53\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1], dtype=torch.int16)\n",
      "65\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "75\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1], dtype=torch.int16)\n",
      "84\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1], dtype=torch.int16)\n",
      "94\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0], dtype=torch.int16)\n",
      "104\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "113\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1], dtype=torch.int16)\n",
      "123\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "132\n",
      "tensor([0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1], dtype=torch.int16)\n",
      "141\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1], dtype=torch.int16)\n",
      "152\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1], dtype=torch.int16)\n",
      "163\n",
      "0.6317829457364341\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1])\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1], dtype=torch.int16)\n",
      "13\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1], dtype=torch.int16)\n",
      "22\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1], dtype=torch.int16)\n",
      "34\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1], dtype=torch.int16)\n",
      "44\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "54\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "64\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1])\n",
      "tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1],\n",
      "       dtype=torch.int16)\n",
      "77\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1])\n",
      "tensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1],\n",
      "       dtype=torch.int16)\n",
      "92\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0], dtype=torch.int16)\n",
      "100\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "108\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "116\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "124\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "133\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "142\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0], dtype=torch.int16)\n",
      "150\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0], dtype=torch.int16)\n",
      "164\n",
      "0.6381322957198443\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1], dtype=torch.int16)\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "18\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "26\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "34\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "42\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "51\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "60\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "69\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0], dtype=torch.int16)\n",
      "77\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "86\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "94\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "102\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "110\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0],\n",
      "       dtype=torch.int16)\n",
      "122\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0], dtype=torch.int16)\n",
      "130\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0], dtype=torch.int16)\n",
      "138\n",
      "0.5872340425531914\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from bert_builder import BERT_ft\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "bert_test = BERT_ft(len(vocabulary_geno), max_length, dim_emb, dim_hidden, attention_heads, num_encoders, drop_prob, len(vocabulary_pheno), device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(bert_test.parameters(), lr=0.001, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = -1).to(device)\n",
    "\n",
    "\n",
    "loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "for i, batch in enumerate(loader):\n",
    "    if i >= 10:\n",
    "        break \n",
    "    optimizer.zero_grad()\n",
    "    input, token_target, attn_mask, AB_idx, SR_class = batch\n",
    "    token_predictions, resistance_predictions = bert_test(input, attn_mask) \n",
    "    result_list = []\n",
    "    for j in range(len(AB_idx)):\n",
    "        result_tensor = torch.full((81,), -1)  # Create tensor filled with -1 values\n",
    "        for idx, value in enumerate(AB_idx[j]):\n",
    "            if value != -1:\n",
    "                result_tensor[value.item()] = SR_class[j][idx]\n",
    "        result_list.append(result_tensor)\n",
    "    ab_loss = 0\n",
    "    pheno_loss = 0\n",
    "    for i, row in enumerate(resistance_predictions):\n",
    "        prediction = row\n",
    "        target = result_list[i]\n",
    "        ab_loss = custom_loss(prediction, target.float()) \n",
    "        pheno_loss += ab_loss\n",
    "    params_before_optimization = copy.deepcopy(bert_test.state_dict())\n",
    "    pheno_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    total_correct = 0\n",
    "    total_sum = 0\n",
    "    list_AB_predictions = []\n",
    "    pred_res = torch.where(resistance_predictions > 0, torch.ones_like(resistance_predictions), torch.zeros_like(resistance_predictions))\n",
    "    for i, row in enumerate(pred_res):\n",
    "        AB_list = 0\n",
    "        AB_list = [elem.item() for elem in AB_idx[i] if elem.item() != -1]\n",
    "        current_abs = []\n",
    "        for ab in AB_list:\n",
    "            current_abs.append(row[ab].item())\n",
    "        current_abs = torch.tensor(current_abs)\n",
    "        current_abs = current_abs.type(torch.int16)\n",
    "        list_AB_predictions.append(current_abs)\n",
    "    \n",
    "        processed_tensor = [row[row != -1] for row in SR_class]\n",
    "    for i, row in enumerate(processed_tensor):\n",
    "        print(row)\n",
    "        print(list_AB_predictions[i])\n",
    "        total_correct += (row == list_AB_predictions[i]).sum().item()\n",
    "        print(total_correct)\n",
    "        total_sum += len(row)\n",
    "    acc = total_correct / total_sum \n",
    "    print(acc)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BertTrainer_ft:\n",
    "    def __init__(self, model, train_set, val_set, epochs, batch_size, lr, device, stop_patience, wandb_mode, project_name, wandb_name):\n",
    "        \n",
    "        self.model = model\n",
    "        self.train_set = train_set\n",
    "        self.train_size = len(train_set)\n",
    "        self.val_set = val_set\n",
    "        self.epochs = epochs    \n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = self.train_size // self.batch_size\n",
    "        self.lr = lr\n",
    "        self.weight_decay = 0.1\n",
    "        self.current_epoch  = 0\n",
    "        self.early_stopping_counter = 0\t\n",
    "        self.patience = stop_patience\n",
    "        \n",
    "        self.wandb_mode = wandb_mode\n",
    "        self.project_name = project_name\n",
    "        self.wandb_name = wandb_name\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        self.token_criterion = nn.CrossEntropyLoss(ignore_index = -1).to(self.device)\n",
    "        self.ab_criterion = nn.BCEWithLogitsLoss().to(self.device)\n",
    "\n",
    "\n",
    "    def __call__(self):   \n",
    "        if self.wandb_mode:\n",
    "            self._init_wandb()   \n",
    "        self.val_set.prepare_dataset() \n",
    "        self.val_loader = DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False)\n",
    "        start_time = time.time()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self._init_result_lists()\n",
    "        for self.current_epoch in range(self.current_epoch, self.epochs):\n",
    "            #Training\n",
    "            self.model.train()\n",
    "            self.train_set.prepare_dataset()\n",
    "            self.train_loader = DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
    "            epoch_start_time = time.time()\n",
    "            avg_epoch_loss_geno, avg_epoch_loss_pheno = self.train(self.current_epoch)\n",
    "            self.train_losses_geno.append(avg_epoch_loss_geno) \n",
    "            self.train_losses_ab.append(avg_epoch_loss_pheno)  \n",
    "            print(f\"Epoch completed in {(time.time() - epoch_start_time)/60:.1f} min\")\n",
    "            \n",
    "            #Validation\n",
    "            print(\"Evaluating on validation set...\")\n",
    "            val_results = self.evaluate(self.val_loader)\n",
    "            print(f\"Elapsed time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))}\")\n",
    "            self.val_losses_geno.append(val_results[0])\n",
    "            self.val_losses_ab.append(val_results[1])\n",
    "            self.val_accs.append(val_results[2])\n",
    "            if self.wandb_mode:\n",
    "                self._report_epoch_results()\n",
    "            criterion = self.stop_early()\n",
    "            if criterion:\n",
    "                print(f\"Training interrupted at epoch: {self.current_epoch+1}\")\n",
    "                break\n",
    "        print(f\"-=Training completed=-\")\n",
    "        results = {\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "            \"geno_train_losses\": self.train_losses_geno,\n",
    "            \"ab_train_losses\": self.train_losses_ab,\n",
    "            \"geno_val_losses\": self.val_losses_geno,\n",
    "            \"ab_val_losses\": self.val_losses_ab,\n",
    "            \"val_accs\": self.val_accs\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    def _init_result_lists(self):\n",
    "\n",
    "        self.train_losses_geno = []\n",
    "        self.train_losses_ab = []\n",
    "\n",
    "        self.val_losses_geno = []\n",
    "        self.val_losses_ab = []\n",
    "\n",
    "        self.val_accs = []\n",
    "    \n",
    "    def stop_early(self):\n",
    "        if self.val_losses_ab[-1] < self.best_val_loss:\n",
    "            self.best_val_loss = self.val_losses_ab[-1]\n",
    "            self.best_epoch = self.current_epoch\n",
    "            self.best_model_state = self.model.state_dict()\n",
    "            self.early_stopping_counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "            return True if self.early_stopping_counter >= self.patience else False\n",
    "\n",
    "    def train(self, epoch: int):\n",
    "        print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "        time_ref = time.time()\n",
    "        \n",
    "        epoch_loss_geno = 0\n",
    "        epoch_loss_pheno = 0\n",
    "\n",
    "        for i, batch in enumerate(self.train_loader):\n",
    "            input, token_target, attn_mask, AB_idx, SR_class = batch\n",
    "            \n",
    "            ABinclusion = torch.unique(AB_idx)\n",
    "            ABinclusion = ABinclusion[ABinclusion != -1]\n",
    "            ABinclusion = ABinclusion.tolist()\n",
    "            #self.model.exclude_networks(ABinclusion)\n",
    "\n",
    "            self.optimizer.zero_grad() \n",
    "\n",
    "            token_predictions, resistance_predictions = self.model(input, attn_mask) \n",
    "            geno_loss = self.token_criterion(token_predictions.transpose(-1, -2), token_target) \n",
    "            \n",
    "            result_list = []\n",
    "            for j in range(len(AB_idx)):\n",
    "                result_tensor = torch.full((81,), -1) \n",
    "                for idx, value in enumerate(AB_idx[j]):\n",
    "                    if value != -1:\n",
    "                        result_tensor[value.item()] = SR_class[j][idx]\n",
    "                result_list.append(result_tensor)\n",
    "            ab_loss = 0\n",
    "            pheno_loss = 0\n",
    "            for i, row in enumerate(resistance_predictions):\n",
    "                prediction = row\n",
    "                target = result_list[i]\n",
    "                ab_loss = custom_loss(prediction, target.float()) \n",
    "                pheno_loss += ab_loss\n",
    "            pheno_loss.backward() \n",
    "            epoch_loss_geno += geno_loss.item()\n",
    "            epoch_loss_pheno += pheno_loss.item()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            #self.model.reset_exclusion()   \n",
    "              \n",
    "\n",
    "        avg_epoch_loss_geno = epoch_loss_geno / self.num_batches\n",
    "        avg_epoch_loss_pheno = epoch_loss_pheno / self.num_batches\n",
    "\n",
    "        return avg_epoch_loss_geno, avg_epoch_loss_pheno\n",
    "\n",
    "    def custom_loss(logits, targets, pad_index=-1):\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        \n",
    "        mask = (targets != pad_index).float()\n",
    "        masked_loss = loss * mask\n",
    "        \n",
    "        average_loss = masked_loss.sum() / mask.sum()\n",
    "        \n",
    "        return average_loss\n",
    "\n",
    "    \n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        epoch_loss_geno = 0\n",
    "        epoch_loss_ab = 0\n",
    "        total_correct = 0\n",
    "        total_sum = 0\n",
    "  \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(loader):\n",
    "                input, token_target, attn_mask, AB_idx, SR_class = batch\n",
    "\n",
    "                token_predictions, resistance_predictions = self.model(input, attn_mask) \n",
    "                geno_loss = self.token_criterion(token_predictions.transpose(-1, -2), token_target) \n",
    "                \n",
    "                result_list = []\n",
    "                for j in range(len(AB_idx)):\n",
    "                    result_tensor = torch.full((81,), -1)  # Create tensor filled with -1 values\n",
    "                    for idx, value in enumerate(AB_idx[j]):\n",
    "                        if value != -1:\n",
    "                            result_tensor[value.item()] = SR_class[j][idx]\n",
    "                    result_list.append(result_tensor)\n",
    "                ab_loss = 0\n",
    "                pheno_loss = 0\n",
    "                for i, row in enumerate(resistance_predictions):\n",
    "                    prediction = row\n",
    "                    target = result_list[i]\n",
    "                    ab_loss = custom_loss(prediction, target.float()) \n",
    "                    pheno_loss += ab_loss\n",
    "                epoch_loss_geno += geno_loss.item()\n",
    "                epoch_loss_ab += pheno_loss.item() \n",
    "                \n",
    "                list_AB_predictions = []\n",
    "                pred_res = torch.where(resistance_predictions > 0, torch.ones_like(resistance_predictions), torch.zeros_like(resistance_predictions))\n",
    "\n",
    "                for i, row in enumerate(pred_res):\n",
    "                    AB_list = 0\n",
    "                    AB_list = [elem.item() for elem in AB_idx[i] if elem.item() != -1]\n",
    "                    current_abs = []\n",
    "                    for ab in AB_list:\n",
    "                        current_abs.append(row[ab].item())\n",
    "                    current_abs = torch.tensor(current_abs)\n",
    "                    current_abs = current_abs.type(torch.int16)\n",
    "                    list_AB_predictions.append(current_abs)\n",
    "                \n",
    "                    processed_tensor = [row[row != -1] for row in SR_class]\n",
    "                for i, row in enumerate(processed_tensor):\n",
    "                    total_correct += (row == list_AB_predictions[i]).sum().item()\n",
    "                    total_sum += len(row)\n",
    "\n",
    "        avg_epoch_loss_geno = epoch_loss_geno / self.num_batches\n",
    "        avg_epoch_loss_ab = epoch_loss_ab / self.num_batches\n",
    "\n",
    "        accuracy = total_correct / total_sum\n",
    "\n",
    "        return avg_epoch_loss_geno, avg_epoch_loss_ab, accuracy\n",
    "    \n",
    "    def _save_model(self, savepath: Path):\n",
    "        torch.save(self.best_model_state, savepath)\n",
    "        print(f\"Model saved to {savepath}\")\n",
    "        \n",
    "        \n",
    "    def _load_model(self, savepath: Path):\n",
    "        print(f\"Loading model from {savepath}\")\n",
    "        self.model.load_state_dict(torch.load(savepath))\n",
    "        print(\"Model loaded\")\n",
    "\n",
    "    def _init_wandb(self):\n",
    "        self.wandb_run = wandb.init(\n",
    "            project=self.project_name, # name of the project\n",
    "            name=self.wandb_name, # name of the run\n",
    "            \n",
    "            config={\n",
    "                \"epochs\": self.epochs,\n",
    "                \"batch_size\": self.batch_size,\n",
    "                \"num_heads\": self.model.attention_heads,\n",
    "                \"num_encoders\": self.model.num_encoders,\n",
    "                \"emb_dim\": self.model.dim_embedding,\n",
    "                'ff_dim': self.model.dim_embedding,\n",
    "                \"lr\": self.lr,\n",
    "                \"weight_decay\": self.weight_decay,\n",
    "                \"max_seq_len\": self.model.max_length[0],\n",
    "                \"vocab_size\": len(self.train_set.vocab_geno),\n",
    "                \"num_parameters\": sum(p.numel() for p in self.model.parameters() if p.requires_grad),\n",
    "            }\n",
    "        )\n",
    "        self.wandb_run.watch(self.model) # watch the model for gradients and parameters\n",
    "        self.wandb_run.define_metric(\"epoch\", hidden=True)\n",
    "        self.wandb_run.define_metric(\"batch\", hidden=True)\n",
    "\n",
    "        self.wandb_run.define_metric(\"GenoLosses/geno_train_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        self.wandb_run.define_metric(\"GenoLosses/geno_val_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "\n",
    "        self.wandb_run.define_metric(\"AB_Losses/ab_train_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        self.wandb_run.define_metric(\"AB_Losses/ab_val_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "\n",
    "        self.wandb_run.define_metric(\"Accuracies/val_acc\", summary=\"min\", step_metric=\"epoch\")\n",
    "        \n",
    "        self.wandb_run.define_metric(\"Losses/final_val_loss\")\n",
    "        self.wandb_run.define_metric(\"Accuracies/final_val_acc\")\n",
    "        self.wandb_run.define_metric(\"final_epoch\")\n",
    "\n",
    "        return self.wandb_run\n",
    "    \n",
    "    def _report_epoch_results(self):\n",
    "        wandb_dict = {\n",
    "            \"epoch\": self.current_epoch+1,\n",
    "            \n",
    "            \"GenoLosses/geno_train_loss\": self.train_losses_geno[-1],\n",
    "            \"ABLosses/ab_train_loss\": self.train_losses_ab[-1],\n",
    "\n",
    "            \"GenoLosses/geno_val_loss\": self.val_losses_geno[-1],\n",
    "            \"ABLosses/ab_val_loss\": self.val_losses_ab[-1],\n",
    "            \n",
    "            \"Accuracies/val_acc\": self.val_accs[-1],\n",
    "        }\n",
    "        self.wandb_run.log(wandb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import data_loader\n",
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "from misc import get_split_indices\n",
    "from create_dataset import NCBIDataset\n",
    "include_pheno = False\n",
    "\n",
    "NCBI,ab_df = data_loader(include_pheno,threshold_year,data_path,ab_path)\n",
    "\n",
    "\n",
    "include_pheno = False\n",
    "max_length = [51,81]\n",
    "mask_prob = 0.25\n",
    "vocabulary_geno = vocab_geno(NCBI, include_pheno)\n",
    "vocabulary_pheno = vocab_pheno(ab_df)\n",
    "\n",
    "test_set = NCBIDataset(NCBI, vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "test_set.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_builder import BERT_pt\n",
    "from trainer import BertTrainer_pt\n",
    "\n",
    "train_indices, val_indices = get_split_indices(len(NCBI), 0.2)\n",
    "train_set = NCBIDataset(NCBI.iloc[train_indices], vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "val_set = NCBIDataset(NCBI.iloc[val_indices], vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BERT_pt(vocab_size=len(vocabulary_geno), max_length=51, dim_embedding = 128, attention_heads=8, num_encoders=2, dropout_prob=0.2)\n",
    "save_directory = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\savefiles'\n",
    "\n",
    "trainer = BertTrainer_pt(model, train_set, val_set, epochs, batch_size, lr, device, stop_patience, save_directory)\n",
    "trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, 6483 samples found\n",
      "length  of token vocabulary: 475\n"
     ]
    }
   ],
   "source": [
    "from bert_builder import BERT_ft\n",
    "from data_preprocessing import data_loader\n",
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "from misc import get_split_indices\n",
    "from create_dataset import NCBIDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "include_pheno = True\n",
    "\n",
    "NCBI,ab_df = data_loader(include_pheno,threshold_year,data_path,ab_path)\n",
    "vocabulary_geno = vocab_geno(NCBI, include_pheno)\n",
    "vocabulary_pheno = vocab_pheno(ab_df)\n",
    "\n",
    "#reduced_samples = 4000\n",
    "#NCBI = NCBI.head(reduced_samples)\n",
    "\n",
    "print(f\"Data loaded, {len(NCBI)} samples found\")\n",
    "print(f\"length  of token vocabulary:\",len(vocabulary_geno))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_indices, val_indices = get_split_indices(len(NCBI), 0.2)\n",
    "train_set = NCBIDataset(NCBI.iloc[train_indices], vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "val_set = NCBIDataset(NCBI.iloc[val_indices], vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:oqhkksk1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ABLosses/ab_train_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>ABLosses/ab_val_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Accuracies/val_acc</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>GenoLosses/geno_train_loss</td><td>ââ âââ âââââ ââââ  ââââââ ââââââââ âââââ</td></tr><tr><td>GenoLosses/geno_val_loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>epoch</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ABLosses/ab_train_loss</td><td>9.59987</td></tr><tr><td>ABLosses/ab_val_loss</td><td>2.18883</td></tr><tr><td>epoch</td><td>50</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MaxSamples_updatedAcc_NonFrozen</strong> at: <a href='https://wandb.ai/strompfel/Trial_runs/runs/oqhkksk1' target=\"_blank\">https://wandb.ai/strompfel/Trial_runs/runs/oqhkksk1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240226_115818-oqhkksk1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:oqhkksk1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: C:\\Users\\erikw\\AppData\\Local\\Temp\\ipykernel_11948\\2021358228.py 223 _init_wandb\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m bert_test \u001b[38;5;241m=\u001b[39m BERT_ft(\u001b[38;5;28mlen\u001b[39m(vocabulary_geno), max_length, dim_emb, dim_hidden, attention_heads, num_encoders, drop_prob, \u001b[38;5;28mlen\u001b[39m(vocabulary_pheno), device)\n\u001b[0;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m BertTrainer_ft(bert_test, train_set, val_set, \u001b[38;5;241m50\u001b[39m, batch_size, lr, device, stop_patience,  \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial_runs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaxSamples_updatedAcc_NonFrozen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 36\u001b[0m, in \u001b[0;36mBertTrainer_ft.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):   \n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb_mode:\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_wandb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_set\u001b[38;5;241m.\u001b[39mprepare_dataset() \n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[40], line 223\u001b[0m, in \u001b[0;36mBertTrainer_ft._init_wandb\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_wandb\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb_run \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# name of the project\u001b[39;49;00m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwandb_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# name of the run\u001b[39;49;00m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_heads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_encoders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_encoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memb_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mff_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_seq_len\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvocab_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_geno\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_parameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb_run\u001b[38;5;241m.\u001b[39mwatch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel) \u001b[38;5;66;03m# watch the model for gradients and parameters\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb_run\u001b[38;5;241m.\u001b[39mdefine_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1199\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n\u001b[0;32m   1198\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterrupted\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m-> 1199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1201\u001b[0m     error_seen \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1176\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1174\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:802\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    798\u001b[0m         tel\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mresumed \u001b[38;5;241m=\u001b[39m run_result\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mresumed\n\u001b[0;32m    800\u001b[0m run\u001b[38;5;241m.\u001b[39m_set_run_obj(run_result\u001b[38;5;241m.\u001b[39mrun)\n\u001b[1;32m--> 802\u001b[0m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting run threads in backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# initiate run (stats and metadata probing)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:2266\u001b[0m, in \u001b[0;36mRun._on_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2262\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunicating current version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2263\u001b[0m version_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mdeliver_check_version(\n\u001b[0;32m   2264\u001b[0m     current_version\u001b[38;5;241m=\u001b[39mwandb\u001b[38;5;241m.\u001b[39m__version__\n\u001b[0;32m   2265\u001b[0m )\n\u001b[1;32m-> 2266\u001b[0m version_result \u001b[38;5;241m=\u001b[39m \u001b[43mversion_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version_result:\n\u001b[0;32m   2268\u001b[0m     version_handle\u001b[38;5;241m.\u001b[39mabandon()\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:283\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[1;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 283\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_and_clear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Always update progress to 100% when done\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle \u001b[38;5;129;01mand\u001b[39;00m progress_sent:\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:130\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_and_clear\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[pb\u001b[38;5;241m.\u001b[39mResult], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[0;32m    129\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m             found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\envs\\exjobb\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "bert_test = BERT_ft(len(vocabulary_geno), max_length, dim_emb, dim_hidden, attention_heads, num_encoders, drop_prob, len(vocabulary_pheno), device)\n",
    "\n",
    "test = BertTrainer_ft(bert_test, train_set, val_set, 50, batch_size, lr, device, stop_patience,  True, \"Trial_runs\", \"MaxSamples_updatedAcc_NonFrozen\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\erikw\\\\Desktop\\\\Exjobb kod\\\\base'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erika\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\magics\\execution.py:726: UserWarning: For Windows, use double quotes to wrap a filename: %run \"mypath\\myfile.py\"\n",
      "  warn('For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"')\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "File `\"'run.py'\"` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\magics\\execution.py:716\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    715\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 716\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\utils\\path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[1;31mOSError\u001b[0m: File `\"'run.py'\"` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124merika\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mExjobb\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrepo\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-i \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\magics\\execution.py:727\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[0;32m    726\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
      "\u001b[1;31mException\u001b[0m: File `\"'run.py'\"` not found."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\repo\\\\base')\n",
    "%run -i 'run.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
