{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from itertools import chain \n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import vocab as Vocab\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pathing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lokalt\n",
    "data_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saga\n",
    "data_dir = \"/home/aeerik/data/raw/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>USA</td>\n",
       "      <td>[sul1, tet(A), aadA1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>USA</td>\n",
       "      <td>[sul2, aph(3'')-Ib, tet(A), aph(6)-Id]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>USA</td>\n",
       "      <td>[glpT_E448K=POINT, pmrB_Y358N=POINT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>[uhpT_E350Q=POINT, cyaA_S352T=POINT, glpT_E448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1979</td>\n",
       "      <td>USA</td>\n",
       "      <td>[glpT_E448K=POINT]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year location                                              genes\n",
       "1  [PAD]      USA                              [sul1, tet(A), aadA1]\n",
       "4  [PAD]      USA             [sul2, aph(3'')-Ib, tet(A), aph(6)-Id]\n",
       "5  [PAD]      USA               [glpT_E448K=POINT, pmrB_Y358N=POINT]\n",
       "6  [PAD]   Sweden  [uhpT_E350Q=POINT, cyaA_S352T=POINT, glpT_E448...\n",
       "7   1979      USA                                 [glpT_E448K=POINT]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_preprocessing import data_loader\n",
    "include_pheno = False\n",
    "threshold_year = 1970\n",
    "path = data_dir\n",
    "\n",
    "NCBI = data_loader(include_pheno,threshold_year,path)\n",
    "NCBI.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n"
     ]
    }
   ],
   "source": [
    "from build_vocabulary import make_vocabulary\n",
    "vocabulary = make_vocabulary(NCBI)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      masked_indices  \\\n",
      "0  [0, 1, 59, 213, 214, 215, 1, 1, 1, 1, 1, 1, 1,...   \n",
      "1  [0, 1, 60, 2, 2, 217, 2, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "2  [0, 1, 59, 219, 220, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
      "3  [0, 1, 60, 221, 222, 220, 1, 1, 1, 1, 1, 1, 1,...   \n",
      "4  [0, 4, 59, 220, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "\n",
      "                                             indices  \n",
      "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
      "1  [-1, -1, -1, 215, 216, -1, 218, -1, -1, -1, -1...  \n",
      "2  [-1, -1, -1, 219, -1, -1, -1, -1, -1, -1, -1, ...  \n",
      "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
      "4  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n"
     ]
    }
   ],
   "source": [
    "from create_dataset import NCBIDataset\n",
    "from build_vocabulary import make_vocabulary\n",
    "from data_preprocessing import data_loader\n",
    "\n",
    "include_pheno = False\n",
    "threshold_year = 1970\n",
    "path = data_dir\n",
    "\n",
    "NCBI = data_loader(include_pheno,threshold_year,path)\n",
    "\n",
    "max_length = 20\n",
    "mask_prob = 0.30\n",
    "vocabulary = make_vocabulary(NCBI)\n",
    "\n",
    "test_set = NCBIDataset(NCBI, vocabulary, max_length, mask_prob)\n",
    "test_set.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class JointEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, vocab_size, max_length, drop_prob):\n",
    "        super(JointEmbedding, self).__init__()\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.drop_prob = drop_prob\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.token_emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\t\n",
    "        self.norm = nn.LayerNorm(self.embedding_dim)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        token_embedding = self.token_emb(input_tensor)\n",
    "        token_embedding = self.norm(token_embedding)\n",
    "        token_embedding = self.dropout(token_embedding)\n",
    "\n",
    "        return token_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0337,  0.9437, -1.0975,  ..., -0.2204,  0.0785, -0.1280],\n",
       "        [-0.3760, -1.7550, -0.4711,  ..., -0.4955,  2.0315, -0.2465],\n",
       "        [ 0.0000, -0.6462, -0.5374,  ..., -1.1704, -0.8540, -1.1201],\n",
       "        ...,\n",
       "        [-0.3760, -1.7550, -0.4711,  ..., -0.0000,  2.0315, -0.2465],\n",
       "        [-0.3760, -1.7550, -0.4711,  ..., -0.4955,  2.0315, -0.2465],\n",
       "        [-0.3760, -1.7550, -0.4711,  ..., -0.0000,  2.0315, -0.2465]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from embedding import JointEmbedding\n",
    "embedding_dim = 512\n",
    "voca_size = len(vocabulary)\n",
    "max_length = 20\n",
    "drop_prob = 0.1 \n",
    "\n",
    "emb_test = JointEmbedding(embedding_dim, voca_size, max_length, drop_prob)\n",
    "emb_test.forward(test_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,  59, 213, 214, 215,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset\n",
    "- behöver vocabulary\n",
    "- saknar: getitem och prepare dataset som kallar på construct_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data importerad\n",
      "här är lugnt\n",
      "[['[CLS]', '[PAD]', 'USA', 'aadA1', 'sul1', 'tet(A)'], ['[CLS]', '[PAD]', 'Sweden', '[MASK]', '[MASK]', 'tet(A)', '[MASK]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT'], ['[CLS]', '[PAD]', 'Sweden', 'glpT_E448K=POINT', 'cyaA_S352T=POINT', 'uhpT_E350Q=POINT'], ['[CLS]', '1979', 'USA', 'glpT_E448K=POINT'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', '[MASK]', '[MASK]'], ['[CLS]', '[PAD]', 'USA', '[MASK]', 'pmrB_E123D=POINT', '[MASK]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT'], ['[CLS]', '[PAD]', 'Sweden', 'parC_A56T=POINT', 'glpT_E448K=POINT', '[MASK]', '[MASK]'], ['[CLS]', '[PAD]', 'Sweden', 'parE_I355T=POINT'], ['[CLS]', '[PAD]', 'Sweden', 'glpT_E448K=POINT'], ['[CLS]', '[PAD]', 'Sweden', \"aph(3'')-Ib\", 'tet(B)', 'sul2', '[MASK]'], ['[CLS]', '[PAD]', 'Indonesia', 'glpT_E448K=POINT'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_E123D=POINT'], ['[CLS]', '[PAD]', 'USA', \"aph(3'')-Ib\", 'glpT_E448K=POINT', 'pmrB_Y358N=POINT', 'aph(6)-Id', 'tet(B)'], ['[CLS]', '1979', 'USA', '[MASK]', '1979', 'pmrB_Y358N=POINT', 'aph(6)-Id', 'aph(6)-Ic'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_E123D=POINT'], ['[CLS]', '[PAD]', 'USA', '[MASK]', 'pmrB_Y358N=POINT'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT']]\n",
      "[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, 216, 217, -1, 218], [-1, -1, -1, 219, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, 219, 223, 224], [-1, -1, -1, 219, -1, 222], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, 225, -1, 215, 220], [-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, 218], [-1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, 216, 219, -1, -1, 227], [-1, -1, -1, -1, -1], [-1, -1, -1, 219, -1], [-1, -1, -1, -1, -1]]\n",
      "[['[CLS]', '[PAD]', 'USA', 'aadA1', 'sul1', 'tet(A)', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'Sweden', '[MASK]', '[MASK]', 'tet(A)', '[MASK]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'Sweden', 'glpT_E448K=POINT', 'cyaA_S352T=POINT', 'uhpT_E350Q=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '1979', 'USA', 'glpT_E448K=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', '[MASK]', '[MASK]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', '[MASK]', 'pmrB_E123D=POINT', '[MASK]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'Sweden', 'parC_A56T=POINT', 'glpT_E448K=POINT', '[MASK]', '[MASK]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'Sweden', 'parE_I355T=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'Sweden', 'glpT_E448K=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'Sweden', \"aph(3'')-Ib\", 'tet(B)', 'sul2', '[MASK]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'Indonesia', 'glpT_E448K=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_E123D=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', \"aph(3'')-Ib\", 'glpT_E448K=POINT', 'pmrB_Y358N=POINT', 'aph(6)-Id', 'tet(B)', '[PAD]', '[PAD]'], ['[CLS]', '1979', 'USA', '[MASK]', '1979', 'pmrB_Y358N=POINT', 'aph(6)-Id', 'aph(6)-Ic', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_E123D=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', '[MASK]', 'pmrB_Y358N=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['[CLS]', '[PAD]', 'USA', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']]\n",
      "range(0, 347995)\n",
      "hit men inte längre \n",
      "                          masked_indices  \\\n",
      "0  [0, 1, 59, 213, 214, 215, 1, 1, 1, 1]   \n",
      "1      [0, 1, 60, 2, 2, 215, 2, 1, 1, 1]   \n",
      "2    [0, 1, 59, 219, 220, 1, 1, 1, 1, 1]   \n",
      "3  [0, 1, 60, 219, 221, 222, 1, 1, 1, 1]   \n",
      "4      [0, 4, 59, 219, 1, 1, 1, 1, 1, 1]   \n",
      "\n",
      "                                       indices  \n",
      "0     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
      "1  [-1, -1, -1, 216, 217, -1, 218, -1, -1, -1]  \n",
      "2    [-1, -1, -1, 219, -1, -1, -1, -1, -1, -1]  \n",
      "3     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
      "4     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab \n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "from data_preprocessing import data_loader\n",
    "\n",
    "include_pheno = True\n",
    "threshold_year = 1970\n",
    "\n",
    "NCBI = data_loader(include_pheno,threshold_year)\n",
    "NCBI.fillna('[PAD]', inplace=True)\n",
    "print('data importerad')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MASK_PERCENTAGE = 0.15\n",
    "\n",
    "\n",
    "# data, vocabulary, max sequence length, mask probability, include sequences, some random state\n",
    "class NCBIDataset(Dataset):\n",
    "\n",
    "    MASKED_INDICES_COLUMN = 'masked_indices'\n",
    "    TARGET_COLUMN = 'indices'\n",
    "    NSP_TARGET_COLUMN = 'is_next'\n",
    "    TOKEN_MASK_COLUMN = 'token_mask'\n",
    "\n",
    "    def __init__(self,\n",
    "                 data: pd.DataFrame,\n",
    "                 vocab: vocab,\n",
    "                 max_seq_len: int,\n",
    "                 mask_prob: float,\n",
    "                 random_state: int = 23,\n",
    "                 ):\n",
    "        \n",
    "        self.random_state = random_state\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        CLS = '[CLS]'\n",
    "        PAD = '[PAD]'\n",
    "        MASK = '[MASK]'\n",
    "        UNK = '[UNK]'\n",
    "\n",
    "        self.data = data.reset_index(drop=True) \n",
    "        self.num_samples = self.data.shape[0]\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.CLS = CLS \n",
    "        self.PAD = PAD\n",
    "        self.MASK = MASK\n",
    "        self.UNK = UNK\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.mask_prob = mask_prob\n",
    "        self.columns = [self.MASKED_INDICES_COLUMN, self.TARGET_COLUMN]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        input = torch.Tensor(item[self.MASKED_INDICES_COLUMN],device=device).long()\n",
    "        token_mask  = torch.tensor(item[self.TARGET_COLUMN], device=device).long()\n",
    "        attention_mask = (input == self.vocab[self.PAD]).unsqueeze(0)\n",
    "\n",
    "        return input, token_mask , attention_mask\n",
    "\n",
    "    def _construct_masking(self):\n",
    "        sequences = deepcopy(self.data['genes'].tolist())\n",
    "        masked_sequences = list()\n",
    "        target_indices_list = list()\n",
    "        seq_starts = [[self.CLS, self.data['year'].iloc[i], self.data['location'].iloc[i]] for i in range(self.data.shape[0])]\n",
    "\n",
    "        for i, geno_seq in enumerate(sequences):\n",
    "            seq_len = len(geno_seq)\n",
    "            masking_index = np.random.rand(seq_len) < self.mask_prob   \n",
    "            target_indices = np.array([-1]*seq_len)\n",
    "            indices = masking_index.nonzero()[0]\n",
    "            target_indices[indices] = self.vocab.lookup_indices([geno_seq[i] for i in indices])\n",
    "            for i in indices:\n",
    "                r = np.random.rand()\n",
    "                if r < 0.8:\n",
    "                    geno_seq[i] = self.MASK\n",
    "                elif r > 0.9:\n",
    "                    geno_seq[i] = self.vocab.lookup_token(np.random.randint(self.vocab_size))\n",
    "            geno_seq = seq_starts[i] + geno_seq\n",
    "            target_indices = [-1]*3 + target_indices.tolist() \n",
    "            masked_sequences.append(geno_seq)\n",
    "            target_indices_list.append(target_indices)\n",
    "        print('här är lugnt')\n",
    "        print(masked_sequences[:20])\n",
    "        print(target_indices_list[:20])\n",
    "        masked_sequences = [seq + [self.PAD]*(self.max_seq_len - len(seq)) for seq in masked_sequences]\n",
    "        print(masked_sequences[:20])\n",
    "        print(range(len(target_indices_list)))\n",
    "        for i in range(len(target_indices_list)):\n",
    "            indices = target_indices_list[i]\n",
    "            padding = [-1] * (self.max_seq_len - len(indices))\n",
    "            target_indices_list[i] = indices + padding\n",
    "        print('hit men inte längre ')\n",
    "        return masked_sequences, target_indices_list \n",
    "        \n",
    "    def prepare_dataset(self):\n",
    "        masked_sequences, target_indices = self._construct_masking()\n",
    "        indices_masked = [self.vocab.lookup_indices(masked_seq) for masked_seq in masked_sequences]\n",
    "\n",
    "        rows = zip(indices_masked, target_indices)\n",
    "        self.data = pd.DataFrame(rows, columns=self.columns)\n",
    "        print(self.data.head())\n",
    "\n",
    "def make_vocabulary(dataset: pd.DataFrame):\n",
    "    CLS = '[CLS]'\n",
    "    PAD = '[PAD]'\n",
    "    MASK = '[MASK]'\n",
    "    UNK = '[UNK]'\n",
    "\n",
    "    token_list = Counter()\n",
    "    data = dataset.copy()\n",
    "\n",
    "    location_tokens = list(dict.fromkeys(list(chain(list(data['location'])))))\n",
    "    year_tokens = list(dict.fromkeys(list(chain(list(data['year'])))))\n",
    "    genes_tokens = list(dict.fromkeys(list(chain(*data['genes']))))\n",
    "   \n",
    "    token_list.update(map(str, year_tokens))\n",
    "    token_list.update(map(str, location_tokens))\n",
    "    token_list.update(map(str, genes_tokens))\n",
    "    vocabulary = vocab(token_list,specials = [CLS, PAD, MASK, UNK])\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "max_length = 10\n",
    "mask_prob = 0.30\n",
    "vocabulary = make_vocabulary(NCBI)\n",
    "\n",
    "test_set = NCBIDataset(NCBI, vocabulary, max_length, mask_prob)\n",
    "test_set.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data importerad\n",
      "här är lugnt\n",
      "[['[CLS]', nan, 'USA', 'sul1', 'tet(A)', 'aadA1'], ['[CLS]', nan, 'Sweden', '[MASK]', '[MASK]', 'aph(6)-Id', '[MASK]'], ['[CLS]', nan, 'USA', 'pmrB_Y358N=POINT', 'glpT_E448K=POINT'], ['[CLS]', nan, 'Sweden', 'uhpT_E350Q=POINT', 'cyaA_S352T=POINT', 'glpT_E448K=POINT'], ['[CLS]', '1979', 'USA', 'glpT_E448K=POINT'], ['[CLS]', nan, 'USA', 'pmrB_E123D=POINT', '[MASK]', '[MASK]'], ['[CLS]', nan, 'USA', '[MASK]', 'pmrB_E123D=POINT', '[MASK]'], ['[CLS]', nan, 'USA', 'pmrB_Y358N=POINT', 'glpT_E448K=POINT'], ['[CLS]', nan, 'USA', 'pmrB_Y358N=POINT', 'glpT_E448K=POINT'], ['[CLS]', nan, 'Sweden', 'pmrB_Y358N=POINT', 'tet(A)', '[MASK]', '[MASK]'], ['[CLS]', nan, 'Sweden', 'parE_I355T=POINT'], ['[CLS]', nan, 'Sweden', 'glpT_E448K=POINT'], ['[CLS]', nan, 'Sweden', 'sul2', \"aph(3'')-Ib\", 'aph(6)-Id', '[MASK]'], ['[CLS]', nan, 'Indonesia', 'glpT_E448K=POINT'], ['[CLS]', nan, 'USA', 'pmrB_E123D=POINT', 'glpT_E448K=POINT'], ['[CLS]', nan, 'USA', 'aph(6)-Id', 'glpT_E448K=POINT', 'pmrB_Y358N=POINT', \"aph(3'')-Ib\", 'tet(B)'], ['[CLS]', '1979', 'USA', '[MASK]', 'nan', 'pmrB_Y358N=POINT', \"aph(3'')-Ib\", \"aph(3')-IIa\"], ['[CLS]', nan, 'USA', 'pmrB_E123D=POINT', 'glpT_E448K=POINT'], ['[CLS]', nan, 'USA', '[MASK]', 'glpT_E448K=POINT'], ['[CLS]', nan, 'USA', 'pmrB_Y358N=POINT', 'glpT_E448K=POINT']]\n",
      "[[-1, -1, -1, -1, -1, -1], [-1, -1, -1, 217, 218, -1, 215], [-1, -1, -1, 220, -1], [-1, -1, -1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, 224, 225, 221], [-1, -1, -1, 222, -1, 221], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, 220, -1, 221, 226], [-1, -1, -1, -1], [-1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, 228], [-1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, 219, 221, -1, -1, 228], [-1, -1, -1, -1, -1], [-1, -1, -1, 220, -1], [-1, -1, -1, -1, -1]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab \n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "from data_preprocessing import data_loader\n",
    "from create_dataset import NCBIDataset\n",
    "\n",
    "include_pheno = True\n",
    "threshold_year = 1970\n",
    "\n",
    "NCBI = data_loader(include_pheno,threshold_year)\n",
    "print('data importerad')\n",
    "\n",
    "def make_vocabulary(dataset: pd.DataFrame):\n",
    "    CLS = '[CLS]'\n",
    "    PAD = '[PAD]'\n",
    "    MASK = '[MASK]'\n",
    "    UNK = '[UNK]'\n",
    "\n",
    "    token_list = Counter()\n",
    "    data = dataset.copy()\n",
    "\n",
    "    location_tokens = list(dict.fromkeys(list(chain(list(data['location'])))))\n",
    "    year_tokens = list(dict.fromkeys(list(chain(list(data['year'])))))\n",
    "    genes_tokens = list(dict.fromkeys(list(chain(*data['genes']))))\n",
    "   \n",
    "    token_list.update(map(str, year_tokens))\n",
    "    token_list.update(map(str, location_tokens))\n",
    "    token_list.update(map(str, genes_tokens))\n",
    "    vocabulary = vocab(token_list,specials = [CLS, PAD, MASK, UNK])\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "max_length = 10\n",
    "mask_prob = 0.30\n",
    "vocabulary = make_vocabulary(NCBI)\n",
    "\n",
    "test_set = NCBIDataset(NCBI, vocabulary, max_length, mask_prob)\n",
    "test_set.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import typing\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer \n",
    "\n",
    "print(list(chain(*NCBI['genes']))[:20])\n",
    "\n",
    "mylist = list(dict.fromkeys(list(chain(*NCBI['genes']))))\n",
    "print(len(mylist))\n",
    "print(mylist[:20])\n",
    "\n",
    "test = list(chain(list(NCBI['year'])))\n",
    "print(test[:40])\n",
    "test = list(dict.fromkeys(list(chain(list(NCBI['year'])))))\n",
    "print(len(test))\n",
    "print(test[:40])\n",
    "\n",
    "test = list(chain(list(NCBI['location'])))\n",
    "print(test[:20])\n",
    "test = list(dict.fromkeys(list(chain(list(NCBI['location'])))))\n",
    "print(len(test))\n",
    "print(test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'nan': 2, '1979': 1, '2013': 1, '1996': 1, '1975': 1, '2009': 1, '1974': 1, '1998': 1, '1983': 1, '2008': 1, '1995': 1, '1989': 1, '2003': 1, '1997': 1, '1994': 1, '2001': 1, '1980': 1, '1970': 1, '1971': 1, '2007': 1, '2004': 1, '2006': 1, '1982': 1, '1991': 1, '1990': 1, '2002': 1, '1988': 1, '1987': 1, '2011': 1, '1986': 1, '1985': 1, '2010': 1, '2005': 1, '2012': 1, '1984': 1, '2000': 1, '2014': 1, '2015': 1, '1999': 1, '1992': 1, '1973': 1, '1981': 1, '1993': 1, '2016': 1, '1972': 1, '1976': 1, '1977': 1, '2017': 1, '1978': 1, '2018': 1, '2019': 1, '2020': 1, '2021': 1, '2022': 1, '2023': 1, '2024': 1, 'USA': 1, 'Sweden': 1, 'Indonesia': 1, 'Canada': 1, 'Papua New Guinea': 1, 'Japan': 1, 'China': 1, 'Germany': 1, 'India': 1, 'Bangladesh': 1, 'Brazil': 1, 'UK': 1, 'Denmark': 1, 'South Korea': 1, 'France': 1, 'Norway': 1, 'Malaysia': 1, 'Slovenia': 1, 'Thailand': 1, 'Italy': 1, 'Israel': 1, 'Austria': 1, 'Belgium': 1, 'Guinea-Bissau': 1, 'Australia': 1, 'Hungary': 1, 'Lebanon': 1, 'Spain': 1, 'Tanzania': 1, 'Hong Kong': 1, 'Kenya': 1, 'Guatemala': 1, 'Netherlands': 1, 'Singapore': 1, 'Colombia': 1, 'Chile': 1, 'Argentina': 1, 'Russia': 1, 'Haiti': 1, 'Egypt': 1, 'Madagascar': 1, 'Pakistan': 1, 'Sri Lanka': 1, 'Cuba': 1, 'Viet Nam': 1, 'Nigeria': 1, 'Burkina Faso': 1, 'Mexico': 1, 'Morocco': 1, 'French Guiana': 1, 'Senegal': 1, 'Iran': 1, 'Dominican Republic': 1, 'Uzbekistan': 1, 'Peru': 1, 'Nepal': 1, 'Portugal': 1, 'Gambia': 1, 'Mali': 1, 'Mozambique': 1, 'South Africa': 1, 'DRC': 1, 'Bolivia': 1, 'Czech Republic': 1, 'Serbia': 1, 'Finland': 1, 'Tonga': 1, 'UAE': 1, 'Ireland': 1, 'Turkey': 1, 'Macedonia': 1, 'Poland': 1, 'Switzerland': 1, 'Saudi Arabia': 1, 'Zambia': 1, 'Brunei': 1, 'Estonia': 1, 'Slovakia': 1, 'Jordan': 1, 'Guam': 1, 'Bulgaria': 1, 'Zaire': 1, 'Venezuela': 1, 'Paraguay': 1, 'Costa Rica': 1, 'Uruguay': 1, 'Uganda': 1, 'New Zealand': 1, 'Taiwan': 1, 'Ghana': 1, 'Laos': 1, 'Tunisia': 1, 'Georgia': 1, 'Somalia': 1, 'Puerto Rico': 1, 'West Bank': 1, 'Burundi': 1, 'Greece': 1, 'Qatar': 1, 'Romania': 1, 'Togo': 1, 'Ecuador': 1, 'Guinea': 1, 'Niger': 1, 'Kosovo': 1, 'Afghanistan': 1, 'Ukraine': 1, 'Croatia': 1, 'Cameroon': 1, 'Myanmar': 1, 'Pacific Ocean': 1, 'Malawi': 1, 'Sudan': 1, 'Latvia': 1, 'Lithuania': 1, 'Algeria': 1, 'Oman': 1, 'Cambodia': 1, 'Philippines': 1, 'Rwanda': 1, 'Kuwait': 1, 'Mongolia': 1, 'Antarctica': 1, 'Gabon': 1, 'Syria': 1, 'Korea': 1, 'Mauritius': 1, 'Belarus': 1, 'Ethiopia': 1, 'Guyana': 1, 'Reunion': 1, 'New Caledonia': 1, 'Guadeloupe': 1, 'Cyprus': 1, 'Luxembourg': 1, 'Atlantic Ocean': 1, 'Benin': 1, 'Kazakhstan': 1, 'Bahrain': 1, 'Angola': 1, 'Botswana': 1, 'Armenia': 1, 'Albania': 1, 'Greenland': 1, 'Jamaica': 1, 'Iraq': 1, 'South Sudan': 1, 'Djibouti': 1, \"Cote d'Ivoire\": 1, 'Gaza Strip': 1, 'Iceland': 1, 'Honduras': 1, 'Svalbard': 1, 'Libya': 1, 'sul1': 1, 'tet(A)': 1, 'aadA1': 1, \"aph(3'')-Ib\": 1, 'aph(6)-Id': 1, 'sul2': 1, 'glpT_E448K=POINT': 1, 'pmrB_Y358N=POINT': 1, 'cyaA_S352T=POINT': 1, 'uhpT_E350Q=POINT': 1, 'parE_D475E=POINT': 1, 'pmrB_E123D=POINT': 1, 'parC_A56T=POINT': 1, 'parE_I355T=POINT': 1, 'tet(B)': 1, 'tet(C)': 1, 'catA1': 1, \"aph(3')-Ia\": 1, 'parC_S57T=POINT': 1, 'aac(3)-VIa': 1, 'blaTEM-1': 1, 'aac(3)-IId': 1, 'gyrA_S83L=POINT': 1, 'blaCMY-2': 1, 'aac(3)-IVa': 1, 'aph(4)-Ia': 1, 'parE_I529L=POINT': 1, 'ptsI_V25I=POINT': 1, 'catB3': 1, 'dfrA1': 1, 'aadA5': 1, 'blaSHV-2A': 1, 'ampC_C-42T=POINT': 1, 'cmlA5': 1, \"ant(2'')-Ia\": 1, 'aadA2': 1, 'dfrA12': 1, 'dfrA14': 1, 'dfrA16': 1, 'blaCARB-2': 1, 'ere(A)': 1, 'tet(M)': 1, 'blaPSE': 1, 'nfsA_Q44STOP=POINT': 1, 'blaHER-3': 1, 'fosA7.5': 1, 'blaTEM': 1, 'nfsA_Q113STOP=POINT': 1, 'marR_S3N=POINT': 1, 'pmrB_E121K=POINT': 1, 'parC_E84G=POINT': 1, 'parC_S80I=POINT': 1, 'catA2': 1, 'gyrA_D87N=POINT': 1, 'mph(A)': 1, 'dfrA17': 1, 'sat2': 1, 'ompF_Q88STOP=POINT': 1, 'parE_S458T=POINT': 1, 'dfrA36': 1, 'floR': 1, 'gyrA_D87Y=POINT': 1, 'aadA22': 1, 'parE_S458A=POINT': 1, 'parC_A108T=POINT': 1, 'blaTEM-10': 1, 'blaOXA-1': 1, 'nfsA_G154E=POINT': 1, 'dfrA5': 1, 'blaCTX-M-15': 1, \"aac(6')-Ib-cr5\": 1, 'parC_E84V=POINT': 1, 'mph(B)': 1, 'ampC_T-32A=POINT': 1, 'gyrA_S83A=POINT': 1, 'dfrA7': 1, 'parC_E84A=POINT': 1, 'soxS_A12S=POINT': 1, \"aac(6')-Ib'\": 1, 'blaOXA-9': 1, 'dfrB1': 1, 'blaTEM-116': 1, 'cmlA1': 1, 'sul3': 1, 'aadA13': 1, 'oqxB': 1, 'oqxA': 1, 'bleO': 1, '16S_A964G=POINT': 1, 'pmrB_V161G=POINT': 1, '23S_T754A=POINT': 1, 'ble': 1, \"aph(3')-IIa\": 1, 'aph(6)-Ic': 1, '16S_A1408G=POINT': 1, '16S_C1192T=POINT': 1, 'folP_P64S=POINT': 1, 'aadA7': 1, '16S_A794G=POINT': 1, '16S_A1055G=POINT': 1, 'parC_S80R=POINT': 1, 'cmlA6': 1, 'blaCTX-M-14': 1, 'blaSHV-1': 1, 'tet(D)': 1, 'pmrB_A159V=POINT': 1, 'parE_L416F=POINT': 1, 'rpoB_H526L=POINT': 1, 'dfrA15': 1, 'blaTEM-181': 1, 'dfrA8': 1, 'lnu(F)': 1, 'gyrA_D87G=POINT': 1, 'blaCMY-23': 1, 'qnrS1': 1, 'dfrB4': 1, 'tufA_Q125R=POINT': 1, 'parC_E84K=POINT': 1, 'rmtB1': 1, 'nfsA_W159STOP=POINT': 1, 'pmrB_T92P=POINT': 1, 'blaI': 1, 'blaPC1': 1, 'ompC_Q171STOP=POINT': 1, 'blaTEM-40': 1, 'aadA6': 1, 'aac(3)-IIe': 1, 'folP_P64A=POINT': 1, 'nfsA_Q67STOP=POINT': 1, 'blaTEM-30': 1, '23S_T2609C=POINT': 1, 'blaKPC-3': 1, 'fabI_F203L=POINT': 1, 'blaSHV-12': 1, \"aac(6')-Ib3\": 1, 'nfsA_G126R=POINT': 1, 'emrR_L113P=POINT': 1, 'blaCTX-M-55': 1, 'marR_A70T=POINT': 1, 'rpoB_Q148L=POINT': 1, 'ftsI_I336IKYRI=POINT': 1, 'blaCTX-M-1': 1, 'msr(E)': 1, 'mph(E)': 1, 'lnu(G)': 1, 'blaTEM-52': 1, 'dfrA25': 1, 'qnrB2': 1, \"aac(2')-IIa\": 1, 'erm(B)': 1, 'parC_A108V=POINT': 1, 'aadA15': 1, 'nfsA_G131D=POINT': 1, 'dfrA4': 1, 'rpoB_V146F=POINT': 1, 'soxR_G121D=POINT': 1, 'blaKPC-2': 1, \"aac(6')-IIc\": 1, 'arr': 1, 'aac(3)-IIg': 1, 'blaSHV': 1, 'acrB_R717L=POINT': 1, 'arr-3': 1, 'blaCTX-M-3': 1, 'qnrA3': 1, 'ompC_Q82STOP=POINT': 1, 'blaCTX-M-27': 1, 'blaNDM-1': 1, \"aac(6')-Ib\": 1, 'blaTEM-33': 1, 'dfrA21': 1, 'aadA4': 1, 'catB11': 1, 'blaFOX-5': 1, 'dfrA19': 1, 'ampC_C-11T=POINT': 1, 'blaTEM-105': 1, 'blaTEM-135': 1, 'folP_F28L=POINT': 1, 'dfrA32': 1, 'qnrB19': 1, 'rmtE1': 1, 'dfrA34': 1, 'nfsA_S33R=POINT': 1, 'blaOXA-181': 1, 'dfrA27': 1, 'qnrB6': 1, 'aadA16': 1, 'blaCTX-M-104': 1, 'blaTEM-19': 1, 'ampC_G-15GG=POINT': 1, 'blaTEM-12': 1, 'nfsB_W94STOP=POINT': 1, 'parE_L445H=POINT': 1, 'gyrA_S83W=POINT': 1, 'gyrA_D87H=POINT': 1, 'blaCMY': 1, 'qnrA1': 1, \"aac(6')-Ib4\": 1, 'fosA4': 1, 'mcr-1.1': 1, 'tet(X5)': 1, 'blaTEM-176': 1, 'mcr-3.1': 1, 'ftsI_N337NYRIN=POINT': 1, 'blaNDM-5': 1, 'blaCMY-42': 1, 'blaNDM': 1, \"aac(6')-Ian\": 1, 'aadA10': 1, 'mef(B)': 1, 'aadA25': 1, 'qnrS2': 1, 'fosA3': 1, 'armA': 1, 'fosA7': 1, 'floR2': 1, 'qnrE4': 1, 'tet(G)': 1, 'tet(Y)': 1, 'aadA12': 1, 'estT': 1, 'dfrA23': 1, 'aadA8': 1, 'aadA31': 1, 'qepA1': 1, 'uhpA_G97D=POINT': 1, 'blaOXA-2': 1, 'fosA': 1, 'blaOXA': 1, 'blaTEM-148': 1, 'rmtB3': 1, 'rpoB_Q513L=POINT': 1, 'rpoB_D516G=POINT': 1, 'blaIMP-4': 1, \"ant(3'')-Ia\": 1, 'blaTEM-32': 1, 'dfrA3b': 1, 'nfsA_R203C=POINT': 1, 'rpoB_S531F=POINT': 1, '23S_G2032A=POINT': 1, 'catB8': 1, 'blaOXA-10': 1, 'blaCMY-58': 1, 'nfsA_R133S=POINT': 1, 'qepA4': 1, 'blaCMY-4': 1, 'nfsA_H11Y=POINT': 1, \"aac(6')-Ib-cr\": 1, 'blaCTX-M-32': 1, 'tet(31)': 1, 'blaCTX-M': 1, 'blaHER': 1, 'blaLAP': 1, 'rmtC': 1, 'blaCMY-6': 1, 'blaOXA-48': 1, \"aph(3')-VI\": 1, 'blaVIM-29': 1, \"aac(6')-Il\": 1, 'arr-2': 1, 'blaCTX-M-24': 1, 'blaIMP-26': 1, 'blaNDM-7': 1, 'parE_E460D=POINT': 1, 'blaVIM-4': 1, 'blaTEM-169': 1, 'mcr-10': 1, 'blaTEM-190': 1, 'ompR_G63V=POINT': 1, 'ampC_T-14TGT=POINT': 1, 'marR_R77L=POINT': 1, 'qnrB1': 1, 'blaTEM-156': 1, 'blaCTX-M-123': 1, 'blaTEM-84': 1, 'qepA7': 1, 'dfrA26': 1, 'qnrS11': 1, 'oqxB29': 1, 'blaCTX-M-65': 1, 'nfsA_E223STOP=POINT': 1, \"aph(3')-VIa\": 1, 'blaIMP-14': 1, 'aacA34': 1, 'soxR_R20H=POINT': 1, \"aph(3')-VIb\": 1, 'qnrB10': 1, 'blaOXA-163': 1, \"aac(6')-Ib-cr7\": 1, 'parE_I464F=POINT': 1, 'fosA8': 1, 'blaTEM-57': 1, 'blaLAP-2': 1, 'basR_G53E=POINT': 1, 'blaTEM-106': 1, 'blaTEM-15': 1, 'blaTEM-17': 1, 'blaTEM-20': 1, 'blaSHV-2': 1, 'rmtB': 1, 'blaEC-15': 1, 'blaTEM-35': 1, 'qnrS13': 1, 'qnrB4': 1, 'blaDHA-1': 1, 'gyrA_S83V=POINT': 1, 'blaTEM-210': 1, 'qnrB7': 1, 'blaTEM-31': 1, 'rpoB_Q513P=POINT': 1, 'blaCTX-M-115': 1, 'basR_L105P=POINT': 1, 'parC_G78C=POINT': 1, \"aac(6')-Ib11\": 1, 'blaTEM-208': 1, 'dfrA29': 1, 'blaOXA-244': 1, 'blaIMP-1': 1, 'ftsI_I336IPYRI=POINT': 1, 'blaTEM-37': 1, 'mcr-1': 1, 'blaCTX-M-166': 1, 'blaKPC-4': 1, 'blaSHV-7': 1, 'aac(3)-Ib': 1, 'blaIMP-27': 1, 'qepA': 1, 'qnrD1': 1, 'blaOXA-4': 1, \"aph(3')-XV\": 1, 'blaSHV-5': 1, 'parE_E460K=POINT': 1, 'blaSCO-1': 1, 'blaSCO': 1, 'hugA': 1, 'pmrB_T156M=POINT': 1, 'blaTEM-3': 1, 'blaOXA-50': 1, 'blaCMY-16': 1, 'aac(3)-Id': 1, 'npmB2': 1, 'blaCMY-7': 1, 'erm(T)': 1, 'qnrS': 1, 'pmrB_E166K=POINT': 1, 'fosA7.2': 1, 'ere(B)': 1, 'blaTEM-209': 1, 'oqxA2': 1, 'oqxB2': 1, 'blaOXA-129': 1, 'erm(C)': 1, 'mph(C)': 1, 'ampC_C-42A=POINT': 1, '16S_G527T=POINT': 1, 'qnrS12': 1, 'erm(42)': 1, 'blaNDM-9': 1, 'blaCTX-M-125': 1, 'blaCMY-140': 1, 'blaCTX-M-267': 1, 'aadA21': 1, 'blaTEMp_C32T=POINT': 1, 'blaCTX-M-8': 1, 'blaCTX-M-9': 1, 'rpoB_R529C=POINT': 1, 'blaTEM-39': 1, 'qnrVC4': 1, 'basR_G53R=POINT': 1, 'parC_S80W=POINT': 1, 'blaTEM-154': 1, 'acrR_R45C=POINT': 1, 'nfsA_R15C=POINT': 1, 'dfrA10': 1, 'aacA16': 1, 'qepA8': 1, 'fosA5': 1, 'blaCTX-M-182': 1, 'mcr-3.4': 1, 'tet(X4)': 1, 'qnrS4': 1, 'blaGES-5': 1, 'blaTEM-215': 1, 'mcr-3.5': 1, 'blaVEB-1': 1, \"aac(6')-Ia\": 1, 'blaCTX-M-2': 1, 'lnu(A)': 1, 'qnrB': 1, 'mcr-10.1': 1, 'fosA2': 1, \"aac(6')-33\": 1, 'blaTEM-171': 1, 'tet(X3)': 1, 'folP_P64L=POINT': 1, 'nfsB_F84S=POINT': 1, 'blaCTX-M-179': 1, 'blaCMY-136': 1, 'blaCTX-M-153': 1, 'nfsA_E75STOP=POINT': 1, 'blaTEM-54': 1, 'tufA_A376V=POINT': 1, 'cmlA4': 1, 'fosA10': 1, 'mcr-1.4': 1, 'mcr-1.7': 1, 'fabI_G93S=POINT': 1, 'fabI_G93V=POINT': 1, 'mcr-1.5': 1, 'blaNDM-4': 1, 'gyrB_D426N=POINT': 1, 'blaKPC-18': 1, 'aac(3)-Ia': 1, 'blaCMY-111': 1, 'blaNDM-6': 1, 'mcr-1.26': 1, 'lnu(C)': 1, 'aadD1': 1, 'blaZ': 1, 'mcr-3.2': 1, 'blaOXA-232': 1, 'mcr-2.3': 1, 'blaTEM-103': 1, 'mcr-3.24': 1, 'aadA3': 1, 'aad9': 1, 'blaKPC': 1, 'blaROB-11': 1, 'parE_P439S=POINT': 1, 'blaTEM-166': 1, 'nfsA_R203L=POINT': 1, 'qepA6': 1, \"aph(3')-Ib\": 1, 'blaTEM-207': 1, 'mcr-5.1': 1, 'catA3': 1, 'gyrA_Q106H=POINT': 1, 'catB2': 1, 'pmrB_RPISLR6del=POINT': 1, 'fosL': 1, 'catB6': 1, 'blaVIM-1': 1, 'blaACC-1': 1, 'qnrVC1': 1, 'blaPER-2': 1, 'dfrA46': 1, 'ble-Sh': 1, 'blaNDM-21': 1, 'blaLAP-1': 1, 'dfrF': 1, 'rmtD1': 1, 'dfrA22': 1, 'tufA_G317D=POINT': 1, 'mcr-3': 1, 'blaCTX-M-64': 1, 'marR_R94S=POINT': 1, 'blaLAT': 1, 'blaCMY-44': 1, 'lon_P403L=POINT': 1, 'acrB_R620C=POINT': 1, 'mef(C)': 1, 'mph(G)': 1, 'blaSFO-1': 1, 'blaCTX-M-132': 1, 'cfr': 1, 'mcr-1.18': 1, 'tet(H)': 1, 'blaVEB-5': 1, 'tet(E)': 1, 'rpoB_H526Y=POINT': 1, 'blaTEM-4': 1, 'blaTEM-5': 1, 'blaTEM-6': 1, 'aac(3)-Ic': 1, 'blaTEM-7': 1, 'blaIMP-6': 1, 'blaTEM-8': 1, 'rpoB_L533P=POINT': 1, 'blaTEM-2': 1, 'blaCMY-24': 1, 'blaTEM-9': 1, 'sat4': 1, 'parC_G78D=POINT': 1, 'qepA9': 1, 'npmB1': 1, 'blaVEB-17': 1, \"aac(6')-IIa\": 1, 'qepA10': 1, 'mcr-1.2': 1, 'pmrB_L14Q=POINT': 1, 'blaCTX-M-134': 1, 'blaCTX-M-174': 1, 'blaCMY-69': 1, 'blaCMY-33': 1, 'pmrB_C84Y=POINT': 1, 'pmrB_L10P=POINT': 1, 'basR_R81S=POINT': 1, 'basR_G53W=POINT': 1, 'pmrB_P94L=POINT': 1, 'basR_G15R=POINT': 1, 'blaCMY-59': 1, 'basR_G53S=POINT': 1, 'pmrB_C84R=POINT': 1, 'pmrB_A159P=POINT': 1, 'basR_R81L=POINT': 1, 'pmrB_E121Q=POINT': 1, 'pmrB_L10R=POINT': 1, 'pmrB_L14R=POINT': 1, 'basR_A80V=POINT': 1, 'basR_G53C=POINT': 1, 'basR_G53A=POINT': 1, 'blaTEM-34': 1, 'marR_R94H=POINT': 1, 'erm(F)': 1, 'blaTEM-214': 1, 'gyrA_D87V=POINT': 1, 'nfsB_G192S=POINT': 1, 'blaCTX-M-199': 1, 'mcr-3.19': 1, 'blaFRI': 1, 'blaCTX-M-33': 1, \"aac(6')-Ib-cr10\": 1, 'qnrE1': 1, 'qnrVC': 1, 'blaCMY-166': 1, 'blaSHV-11': 1, 'cmlA': 1, 'ompF_G141D=POINT': 1, 'catB': 1, 'rmtF1': 1, 'qepA2': 1, 'blaTEM-71': 1, 'blaTEM-79': 1, 'qnrB17': 1, 'blaGES-7': 1, 'erm(52)': 1, 'blaSHV-210': 1, 'marR_R77C=POINT': 1, 'blaDHA-7': 1, 'erm(G)': 1, 'blaCTX-M-101': 1, 'blaCTX-M-22': 1, 'blaCTX-M-61': 1, 'blaCTX-M-28': 1, 'blaOXA-21': 1, 'blaACC': 1, 'blaOXA-204': 1, 'blaSHV-108': 1, 'qnrB91': 1, 'marR_R73C=POINT': 1, 'blaOXA-427': 1, 'marR_V45E=POINT': 1, 'rmtE2': 1, 'blaNDM-24': 1, 'blaOXA-17': 1, 'blaGES-6': 1, 'blaTEM-191': 1, 'blaCMY-146': 1, 'blaCMY-148': 1, 'marR_L78M=POINT': 1, 'blaSHV-44': 1, 'dfrA30': 1, 'blaTEM-63': 1, 'blaTEM-242': 1, 'blaOXA-58': 1, 'mcr-1.9': 1, 'blaNDM-19': 1, 'blaNDM-13': 1, 'dfrA3': 1, 'blaTEM-238': 1, 'nfsB_G192D=POINT': 1, 'blaNDM-16b': 1, 'blaCTX-M-98': 1, 'qnrB77': 1, 'blaCMY-141': 1, '16S_G926T=POINT': 1, 'blaTEM-198': 1, 'mcr-5': 1, '23S_G2057A=POINT': 1, 'nfsA_K141STOP=POINT': 1, 'blaCTX-M-136': 1, 'blaCTX-M-5': 1, 'blaCTX-M-206': 1, 'blaCMY-32': 1, 'blaTEM-29': 1, 'blaCTX-M-88': 1, 'rpoB_I572L=POINT': 1, 'gyrA_G81D=POINT': 1, 'mcr-3.20': 1, 'blaDHA': 1, 'rpoB_L511Q=POINT': 1, 'blaIMP': 1, 'parE_D476N=POINT': 1, 'blaNDM-27': 1, 'dfrG': 1, 'catA': 1, \"aac(6')-Ie/aph(2'')-Ia\": 1, 'basR_S39I=POINT': 1, \"aph(3')-IIIa\": 1, 'pmrB_G206D=POINT': 1, 'mcr-4.2': 1, 'blaOXA-23': 1, 'blaACT': 1, 'erm(53)': 1, 'blaCTX-M-71': 1, 'blaCTX-M-189': 1, 'blaCMY-43': 1, 'blaCTX-M-157': 1, 'pmrB_P94S=POINT': 1, 'qnrD': 1, 'blaNDM-20': 1, 'qnrB52': 1, 'blaCTX-M-73': 1, 'blaCTX-M-90': 1, 'basR_G53V=POINT': 1, 'gyrA_G81C=POINT': 1, 'tet(X2)': 1, 'aadS': 1, 'aacA37': 1, 'blaPDC': 1, 'blaOXA-488': 1, 'blaCTX-M-130': 1, '23S_C2611T=POINT': 1, 'pmrB_P94Q=POINT': 1, 'tet(K)': 1, 'mcr-4.6': 1, \"aac(6')-Ib-cr4\": 1, 'blaMOX-9': 1, 'estX/sat2': 1, 'blaIMP-11': 1, 'blaCMY-133': 1, 'blaCTX-M-186': 1, 'blaCMY-145': 1, 'tet(J)': 1, 'dfrE': 1, 'rpoB_P564L=POINT': 1, 'blaCTX-M-190': 1, \"aac(6')-Ib-cr9\": 1, 'tet(Q)': 1, '16S_T1406A=POINT': 1, 'blaCTX-M-79': 1, 'aadE': 1, 'rpoB_T563P=POINT': 1, 'blaVEB-25': 1, 'dfrA33': 1, 'blaVIM-2': 1, 'blaVEB-9': 1, 'blaOXA-20': 1, 'blaCTX-M-218': 1, 'fosL1': 1, 'mcr-1.27': 1, 'blaCTX-M-216': 1, 'aphA16': 1, 'qnrA': 1, 'dfrA9': 1, 'pmrB_P94A=POINT': 1, 'emrR_L64R=POINT': 1, 'blaCMY-132': 1, 'blaCMY-62': 1, 'tet(32)': 1, 'blaCMY-154': 1, 'blaTEM-28': 1, 'blaCTX-M-232': 1, 'blaTEM-219': 1, 'fosL2': 1, 'tet(39)': 1, 'rmtG': 1, 'blaCTX-M-12': 1, 'tufA_R334C=POINT': 1, 'tufA_Y161N=POINT': 1, 'blaTEM-122': 1, 'blaCTX-M-165': 1, '16S_G926A=POINT': 1, 'ompF_L15STOP=POINT': 1, 'blaVIM': 1, 'aadA9': 1, 'mcr-1.28': 1, 'blaCMY-162': 1, 'msr(A)': 1, 'blaR1': 1, 'tet(38)': 1, 'parE_I444F=POINT': 1, 'blaCTX-M-240': 1, 'blaTEMp_G162T=POINT': 1, 'gyrA_D82G=POINT': 1, 'blaTEM-183': 1, 'rpoB_I572F=POINT': 1, 'gyrA_A84P=POINT': 1, 'blaCTX-M-215': 1, 'blaCMY-60': 1, 'mcr-3.39': 1, 'toprJ': 1, 'tmexC': 1, 'tmexD': 1, 'tmexC3': 1, 'toprJ1': 1, 'mcr-3.29': 1, 'mcr-1.32': 1, 'tet(O)': 1, 'blaTEM-237': 1, 'blaPER-7': 1, 'blaCTX-M-191': 1, 'blaCTX-M-127': 1, 'blaCMY-131': 1, 'blaTEM-36': 1, 'cirA_R86S=POINT': 1, 'blaCMY-143': 1, 'blaCTX-M-231': 1, 'blaCTX-M-39': 1, 'blaARL': 1, 'fosB6': 1, 'blaOXA-484': 1, 'blaOXA-162': 1, 'mcr-4': 1, 'mcr-4.5': 1, 'mcr-4.1': 1, 'blaCMY-153': 1, 'mcr-5.3': 1, 'cmlA10': 1, 'dfrB3': 1, 'blaSHV-30': 1, 'catB9': 1, 'rmtF': 1, 'blaCTX-M-62': 1, 'blaCTX-M-44': 1, 'blaVEB-3': 1, 'parC_A85T=POINT': 1, 'blaEC-13': 1, 'blaSHV-31': 1, 'blaADC-265': 1, 'blaOXA-832': 1, 'tetB(58)': 1, 'tetA(58)': 1, 'vgbC': 1, 'blaOXA-283': 1, 'blaOXA-1181': 1, 'mcr-2.1': 1, 'blaTEM-168': 1, 'blaCTX-M-235': 1, 'tufA_R231V=POINT': 1, 'blaFONA': 1, 'blaKPC-49': 1, 'blaCMH': 1, 'cepA': 1, \"aph(7'')-Ia\": 1, 'blaTEM-231': 1, 'blaTEM-141': 1, 'blaCTX-M-196': 1, 'blaCTX-M-105': 1, 'blaCTX-M-19': 1, 'aadA11': 1, 'vanH-A': 1, 'vanS-A': 1, 'vga(A)': 1, 'blaGES': 1, 'blaGES-20': 1, 'blaCTX-M-42': 1, 'blaOXA-347': 1, 'blaTEM-132': 1, 'fosE': 1, \"aac(6')-31\": 1, \"ant(3'')-IIa\": 1, 'fosA7.7': 1, 'blaCMY-75': 1, 'blaCTX-M-56': 1, 'sat3': 1, \"aph(3')-Id\": 1, 'erm(49)': 1, 'blaTEM-83': 1, 'dfrB2': 1, 'aac(3)-If': 1, 'blaTEM-150': 1, 'blaCTX-M-82': 1, 'blaMOX': 1, 'blaCMY-27': 1, 'blaCTX-M-121': 1, 'lsa(A)': 1, 'tet(L)': 1, 'blaCTX-M-137': 1, 'blaPER-1': 1, 'blaNDM-3': 1, 'lsa(C)': 1, 'msr(D)': 1, 'tetB(60)': 1, 'mef(A)': 1, 'blaCTX-M-178': 1, 'blaCTX-M-255': 1, 'blaCTX-M-40': 1, 'qnrB38': 1, 'mcr-1.20': 1, 'blaL1': 1, 'blaCTX-M-140': 1, 'blaSHV-120': 1, \"aac(6')-Iai\": 1, 'tet(W)': 1, 'blaTEM-76': 1, 'ant(9)-Ia': 1, 'erm(A)': 1, 'qnrD2': 1, 'spw': 1, 'ant(6)-Ia': 1, 'lnu(B)': 1, 'str': 1, 'lsa(E)': 1, 'cmx': 1, 'blaGES-11': 1, 'blaNDM-36': 1, 'blaNDM-37': 1, 'blaACC-1d': 1, 'blaADC-2': 1, 'blaCTX-M-223': 1, 'blaCMY-10': 1, 'blaOXA-392': 1, 'blaCTX-M-243': 1, 'blaTEM-77': 1, 'mcr-2.8': 1, 'blaCMY-173': 1, 'dfrA35': 1, 'blaIMI-2': 1, \"aac(6')-Iq\": 1, 'mcr-1.11': 1, 'tmexD1': 1, 'tmexC1': 1, 'blaNDM-15': 1, 'blaIMP-64': 1, 'blaTEM-251': 1, 'mcr-3.21': 1, 'blaNDM-33': 1, 'catB1': 1, 'blaIMP-38': 1, 'fosC2': 1, 'blaNDM-29': 1, 'blaTEM-234': 1, 'aacA43': 1, 'blaIMP-18': 1, 'blaKPC-45': 1, 'tmexD3': 1, 'mcr-1.12': 1, 'mcr-1.31': 1, 'mcr-1.34': 1, 'blaIMP-8': 1, 'fabI_G93A=POINT': 1, 'blaACC-1a': 1, 'qnrB9': 1, 'blaNDM-39': 1, 'blaCTX-M-58': 1, 'blaFOX-14': 1, 'blaTEM-185': 1, 'blaNDM-12': 1, 'blaSED': 1, 'blaCTX-M-193': 1, 'blaSHV-161': 1, 'blaSHV-154': 1, 'marR_V96E=POINT': 1, 'rmtB4': 1, 'blaKPC-21': 1, 'blaCMY-156': 1, 'blaOXA-245': 1, 'cblA': 1, 'blaCMY-172': 1, 'mcr-1.8': 1, 'blaOXA-1213': 1, 'blaVIM-86': 1, 'blaCMY-13': 1, 'blaPER-3': 1, 'blaCTX-M-252': 1, \"aac(6')-29\": 1, 'blaKPC-6': 1, 'gyrA_A196E=POINT': 1, 'mcr-1.33': 1, 'msr(C)': 1, \"aac(6')-I\": 1, 'rmtB2': 1, 'marR_E31STOP=POINT': 1, 'blaCTX-M-143': 1, 'blaNDM-48': 1, 'blaGES-1': 1, 'blaGES-2': 1, 'qnrA6': 1, 'blaSHV-26': 1, 'blaCTX-M-169': 1, 'blaIMP-59': 1, 'blaVIM-23': 1, 'blaTEM-143': 1, 'aacA56': 1, 'blaOXA-1041': 1, 'blaCTX-M-63': 1, 'cfxA': 1, 'nimE': 1, 'satA': 1, 'oqxB32': 1, 'vmlR': 1, 'blaCMY-25': 1, 'blaOXA-1042': 1, 'blaTEM-80': 1, 'blaTEM-81': 1, 'blaCTX-M-150': 1, 'blaCMY-121': 1, 'qnrE2': 1, 'blaCTX-M-170': 1, 'blaCTX-M-195': 1, 'blaMIR-22': 1, 'blaCTX-M-96': 1, 'blaCTX-M-214': 1, 'blaTEM-70': 1, 'blaKPC-31': 1, 'blaSHV-49': 1, 'blaOXA-926': 1, 'blaCARB-12': 1, 'tufA_L121Q=POINT': 1, 'mcr-4.3': 1, 'gar': 1, 'ampC_C-42G=POINT': 1, 'blaOXA-101': 1, 'blaCMY-8b': 1, 'blaCTX-M-25': 1, 'blaCTX-M-202': 1, 'blaCTX-M-35': 1, 'parC_E84R=POINT': 1, \"aac(6')\": 1, 'marR_R73S=POINT': 1, 'blaDHA-6': 1, 'vanH-B': 1, 'vanX-B': 1, 'vanB': 1, 'vanR-B': 1, 'vanY-B': 1, 'vanS-B': 1, 'vanW-B': 1, 'dfrA45': 1, 'blaVEB-8': 1, 'tetB(P)': 1, 'blaCFE': 1, 'blaSRT-2': 1, 'blaNDM-55': 1, 'blaCMY-178': 1, 'blaCTX-M-102': 1, 'blaOXA-1205': 1, 'blaTEM-240': 1, 'blaNDM-35': 1, 'blaTEM-26': 1, 'blaOXA-1207': 1, 'blaOXA-24': 1, 'gyrA_A84V=POINT': 1, \"aph(3')-IIb\": 1, 'blaOXA-851': 1, 'crpP': 1, 'catB7': 1, 'blaACT-15': 1, 'blaCMY-101': 1, 'blaNDM-57': 1, 'qnrB65': 1, 'blaIMP-66': 1, 'blaCTX-M-67': 1, 'ftsI_A498T=POINT': 1, 'blaTEM-236': 1, 'blaDHA-27': 1, 'blaCTX-M-200': 1, 'blaCTX-M-269': 1, 'blaCTX-M-30': 1, 'blaCTX-M-52': 1, 'blaKLUC-3': 1, 'blaOXA-932': 1, 'blaCTX-M-38': 1, 'blaNDM-56': 1, '16S_C1066T=POINT': 1, 'blaVEB': 1, 'rpoB_I572N=POINT': 1, 'vga(A)-LC': 1, 'blaFOX': 1, 'parC_S80Y=POINT': 1, 'blaACC-1c': 1, 'blaCTX-M-192': 1, 'blaCMY-185': 1, 'blaCTX-M-220': 1, 'fosI': 1, \"ant(4')-IIb\": 1, 'blaCTX-M-238': 1, 'blaSHV-8': 1, 'blaSHV-102': 1, 'blaCTX-M-36': 1, 'blaOXA-72': 1, 'blaEC-18': 1, 'blaSHV-230': 1, 'blaTEM-244': 1, 'blaTEMp_C141G=POINT': 1, 'blaVIM-24': 1, 'rmtH': 1, 'tetA(P)': 1, 'blaNDM-26': 1, 'mcr-8.1': 1, 'blaCMY-82': 1, \"aph(3')-I(H957)\": 1, 'blaOXY-1-1': 1})\n",
      "Vocab()\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import typing\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer \n",
    "\n",
    "def make_vocabulary(dataset: pd.DataFrame):\n",
    "    CLS = '[CLS]'\n",
    "    PAD = '[PAD]'\n",
    "    SEP = '[SEP]'\n",
    "    MASK = '[MASK]'\n",
    "    UNK = '[UNK]'\n",
    "\n",
    "    token_list = Counter()\n",
    "    data = dataset.copy()\n",
    "\n",
    "    location_tokens = list(dict.fromkeys(list(chain(list(data['location'])))))\n",
    "    year_tokens = list(dict.fromkeys(list(chain(list(data['year'])))))\n",
    "    genes_tokens = list(dict.fromkeys(list(chain(*data['genes']))))\n",
    "   \n",
    "    token_list.update(map(str, year_tokens))\n",
    "    token_list.update(map(str, location_tokens))\n",
    "    token_list.update(map(str, genes_tokens))\n",
    "    print(token_list)\n",
    "    vocabulary = vocab(token_list,specials = [CLS, PAD, MASK, SEP, UNK])\n",
    "    print(vocabulary)\n",
    "    return vocabulary\n",
    "vocabulary = make_vocabulary(NCBI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = make_vocabulary(NCBI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
