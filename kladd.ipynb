{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from itertools import chain \n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import vocab as Vocab\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pathing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lokalt\n",
    "data_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\data'\n",
    "ab_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\repo\\\\base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stationär\n",
    "data_dir = 'c:\\\\Users\\\\erikw\\\\Desktop\\\\Exjobb kod\\\\data'\n",
    "ab_dir = 'c:\\\\Users\\\\erikw\\\\Desktop\\\\Exjobb kod\\\\base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saga\n",
    "data_dir = \"/home/aeerik/data/raw/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget config file\n",
    "include_pheno = False\n",
    "threshold_year = 1970\n",
    "data_path = data_dir\n",
    "ab_path = ab_dir\n",
    "max_length = [51,37]\n",
    "mask_prob = 0.15\n",
    "embedding_dim = 32\n",
    "drop_prob = 0.2\n",
    "\n",
    "#Encoder\n",
    "enc_dim_inp = 32 \n",
    "enc_dim_out = 32 \n",
    "attention_heads = 8 \n",
    "\n",
    "#BERT\n",
    "num_encoders = 2\n",
    "\n",
    "#trainer\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "stop_patience = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "include_pheno = False\n",
    "vocabulary = vocab_geno(NCBI, include_pheno)\n",
    "vocab = vocab_pheno(ab_df)\n",
    "print(len(vocabulary))\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_vocabulary import vocab_geno\n",
    "from build_vocabulary import vocab_pheno\n",
    "from data_preprocessing import data_loader\n",
    "from data_preprocessing import NCBIDataset\n",
    "\n",
    "include_pheno = True\n",
    "threshold_year = 1970\n",
    "\n",
    "data_path = data_dir\n",
    "ab_path = ab_dir\n",
    "\n",
    "NCBI,ab_df = data_loader(include_pheno,threshold_year,data_path,ab_path)\n",
    "\n",
    "max_length = [51,37]\n",
    "mask_prob = 0.25\n",
    "vocabulary_geno = vocab_geno(NCBI, include_pheno)\n",
    "vocabulary_pheno = vocab_pheno(ab_df)\n",
    "\n",
    "test_set = NCBIDataset(NCBI, vocabulary_geno, vocabulary_pheno, max_length, mask_prob,include_pheno)\n",
    "test_set.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16, 29, 72, 69, 25, 45, 78, 54,  2,  5, 66, 22, 42,  3, 30, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1])\n",
      "[16, 29, 72, 69, 25, 45, 78, 54, 2, 5, 66, 22, 42, 3, 30]\n",
      "tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "test_tensor = test_set[5][3]\n",
    "print(test_tensor)\n",
    "test_tensor = test_tensor[test_tensor != -1]\n",
    "print(  test_tensor.tolist()  )\n",
    "\n",
    "selected = pred_res[test_tensor.tolist() ]\n",
    "print(selected)\n",
    "expected = test_set[5][4]\n",
    "expected = expected[expected != -1] \n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from bert_builder import BERT_ft\n",
    "\n",
    "loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "for i, batch in enumerate(loader):\n",
    "    input, token_target, attn_mask, AB_idx, SR_class  = batch\n",
    "    bert_test = BERT_ft(vocab_size=len(vocabulary_geno), max_length=51, dim_embedding = 128, dim_hidden= 128, attention_heads=8, num_encoders=2, dropout_prob=0.2, num_ab=81, device=device)\n",
    "    res_pred = bert_test.forward(input, attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0435,  0.9513,  0.3644, -0.0901, -0.7001, -0.0680, -0.1490, -0.0619,\n",
      "        -0.1270, -0.8133, -0.1457,  0.2177, -0.6492,  0.1714, -0.4112, -0.3951,\n",
      "         0.3892, -0.2889,  0.0415, -0.8135, -0.2810,  0.7298,  0.6785,  0.1533,\n",
      "        -0.6075,  0.2196, -0.1743, -0.8824, -0.6209,  0.5175, -0.1205,  0.8606,\n",
      "         0.2940,  0.5152,  0.5396,  0.3415, -0.6014, -0.4751,  0.0466, -0.4792,\n",
      "         0.3310, -0.5104,  0.0227, -0.4278,  0.4219,  0.3178,  0.0415, -0.9904,\n",
      "         0.5631, -0.3809,  0.6884,  0.0810,  1.2024,  0.3498,  0.1946,  0.8521,\n",
      "         0.9092, -0.1204,  0.8237,  0.4910,  0.7333, -0.4589,  0.3011,  0.3034,\n",
      "         0.3296, -0.0346, -0.5093,  0.8257, -0.2093,  0.0155, -0.4725,  0.4390,\n",
      "        -0.1331,  1.2029, -0.1866,  0.4317,  0.7898,  0.6166, -0.8400,  0.4163,\n",
      "        -0.3838], grad_fn=<SelectBackward0>)\n",
      "tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([1., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "test = res_pred[14]\n",
    "print(test)\n",
    "pred_res = torch.where(test > 0, torch.ones_like(test), torch.zeros_like(test))\n",
    "print(pred_res)\n",
    "indicies = [1,2,3,4]\n",
    "test = pred_res[indicies]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from create_dataset import NCBIDataset\n",
    "def get_split_indices(size_to_split, val_share, random_state: int = 42):\n",
    "    indices = np.arange(size_to_split)\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_share = 1 - val_share\n",
    "    \n",
    "    train_size = int(train_share * size_to_split)\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "    \n",
    "    return train_indices, val_indices\n",
    "max_length = 20\n",
    "mask_prob = 0.30\n",
    "vocabulary = make_vocabulary(NCBI)\n",
    "\n",
    "train_indices, val_indices = get_split_indices(len(NCBI), 0.2)\n",
    "train_set = NCBIDataset(NCBI.iloc[train_indices], vocabulary, max_length, mask_prob)\n",
    "val_set = NCBIDataset(NCBI.iloc[val_indices], vocabulary, max_length, mask_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "class BertTrainer_pt:\n",
    "    def __init__(self, model, train_set, val_set, epochs, batch_size, lr, device, stop_patience, wandb_mode, project_name, wandb_name):\n",
    "        \n",
    "        self.model = model\n",
    "        self.train_set = train_set\n",
    "        self.train_size = len(train_set)\n",
    "        self.val_set = val_set\n",
    "        self.epochs = epochs    \n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = self.train_size // self.batch_size\n",
    "        self.lr = lr\n",
    "        self.weight_decay = 0.01\n",
    "        self.current_epoch  = 0\n",
    "        self.early_stopping_counter = 0\t\n",
    "        self.patience = stop_patience\n",
    "        \n",
    "        \n",
    "        self.wandb_mode = wandb_mode\n",
    "        self.project_name = project_name\n",
    "        self.wandb_name = wandb_name\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index = -1).to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def __call__(self):   \n",
    "        if self.wandb_mode:\n",
    "            self._init_wandb()   \n",
    "        self.val_set.prepare_dataset() \n",
    "        self.val_loader = DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False)\n",
    "        start_time = time.time()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self._init_result_lists()\n",
    "        for self.current_epoch in range(self.current_epoch, self.epochs):\n",
    "            #Training\n",
    "            self.model.train()\n",
    "            self.train_set.prepare_dataset()\n",
    "            self.train_loader = DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
    "            epoch_start_time = time.time()\n",
    "            avg_epoch_loss = self.train(self.current_epoch)\n",
    "            self.train_losses.append(avg_epoch_loss) \n",
    "            print(f\"Epoch completed in {(time.time() - epoch_start_time)/60:.1f} min\")\n",
    "            \n",
    "            #Validation\n",
    "            print(\"Evaluating on validation set...\")\n",
    "            val_results = self.evaluate(self.val_loader)\n",
    "            print(f\"Elapsed time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))}\")\n",
    "            self.val_losses.append(val_results[0])  \n",
    "            self.val_accs.append(val_results[1])\n",
    "            if self.wandb_mode:\n",
    "                self._report_epoch_results()\n",
    "            self._report_epoch_results()\n",
    "            criterion = self.stop_early()\n",
    "            if criterion:\n",
    "                print(f\"Training interrupted at epoch: {self.current_epoch+1}\")\n",
    "                break\n",
    "\n",
    "        print(f\"-=Training completed=-\")\n",
    "        results = {\n",
    "            \"best_epoch\": self.current_epoch,\n",
    "            \"train_losses\": self.train_losses,\n",
    "            \"val_losses\": self.val_losses,\n",
    "            \"val_accs\": self.val_accs\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    def _init_result_lists(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_accs = []\n",
    "    \n",
    "    def stop_early(self):\n",
    "        if self.val_losses[-1] < self.best_val_loss:\n",
    "            self.best_val_loss = self.val_losses[-1]\n",
    "            self.best_epoch = self.current_epoch\n",
    "            self.best_model_state = self.model.state_dict()\n",
    "            self.early_stopping_counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "            return True if self.early_stopping_counter >= self.patience else False\n",
    "\n",
    "    def train(self, epoch: int):\n",
    "        print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "        time_ref = time.time()\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        for i, batch in enumerate(self.train_loader):\n",
    "            input, token_target, attn_mask, AB_idx, SR_class  = batch\n",
    "            \n",
    "            self.optimizer.zero_grad() \n",
    "\n",
    "            tokens, res_pred = self.model(input, attn_mask) \n",
    "            loss = self.criterion(tokens.transpose(-1, -2), token_target) \n",
    "            \n",
    "            epoch_loss += loss.item() \n",
    "            \n",
    "            loss.backward() \n",
    "            self.optimizer.step()         \n",
    "        avg_epoch_loss = epoch_loss / self.num_batches\n",
    "        return avg_epoch_loss \n",
    "    \n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        total_correct = 0\n",
    "        total_tokens = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(loader):\n",
    "                input, token_target, attn_mask = batch\n",
    "                tokens = self.model(input, attn_mask)\n",
    "                loss = self.criterion(tokens.transpose(-1, -2), token_target)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                token_mask =  token_target != -1\n",
    "                predicted_tokens = tokens.argmax(dim=-1)\n",
    "                token_target = torch.masked_select(token_target, token_mask)\n",
    "                predicted_tokens = torch.masked_select(predicted_tokens, token_mask)\n",
    "                \n",
    "                correct = (predicted_tokens == token_target).sum().item()\n",
    "                total_correct += correct\n",
    "                total_tokens += token_target.numel() \n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(loader)\n",
    "        accuracy = total_correct / total_tokens\n",
    "\n",
    "        return avg_epoch_loss, accuracy\n",
    "    \n",
    "    def _save_model(self, savepath: Path):\n",
    "        torch.save(self.best_model_state, savepath)\n",
    "        print(f\"Model saved to {savepath}\")\n",
    "        \n",
    "        \n",
    "    def _load_model(self, savepath: Path):\n",
    "        print(f\"Loading model from {savepath}\")\n",
    "        self.model.load_state_dict(torch.load(savepath))\n",
    "        print(\"Model loaded\")\n",
    "\n",
    "    def _init_wandb(self):\n",
    "        self.wandb_run = wandb.init(\n",
    "            project=self.project_name, # name of the project\n",
    "            name=self.wandb_name, # name of the run\n",
    "            \n",
    "            config={\n",
    "                \"epochs\": self.epochs,\n",
    "                \"batch_size\": self.batch_size,\n",
    "                \"num_heads\": self.model.attention_heads,\n",
    "                \"num_encoders\": self.model.num_encoders,\n",
    "                \"emb_dim\": self.model.dim_inp,\n",
    "                'ff_dim': self.model.dim_out,\n",
    "                \"lr\": self.lr,\n",
    "                \"weight_decay\": self.weight_decay,\n",
    "                \"max_seq_len\": self.model.max_length[0],\n",
    "                \"vocab_size\": len(self.train_set.vocab),\n",
    "                \"num_parameters\": sum(p.numel() for p in self.model.parameters() if p.requires_grad),\n",
    "            }\n",
    "        )\n",
    "        self.wandb_run.watch(self.model) # watch the model for gradients and parameters\n",
    "        self.wandb_run.define_metric(\"epoch\", hidden=True)\n",
    "        self.wandb_run.define_metric(\"batch\", hidden=True)\n",
    "\n",
    "        self.wandb_run.define_metric(\"Losses/train_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        self.wandb_run.define_metric(\"Losses/val_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        \n",
    "        self.wandb_run.define_metric(\"Losses/final_val_loss\")\n",
    "        self.wandb_run.define_metric(\"Accuracies/final_val_acc\")\n",
    "        self.wandb_run.define_metric(\"final_epoch\")\n",
    "\n",
    "        return self.wandb_run\n",
    "    \n",
    "    def _report_epoch_results(self):\n",
    "        wandb_dict = {\n",
    "            \"epoch\": self.current_epoch+1,\n",
    "            \"Losses/train_loss\": self.train_losses[-1],\n",
    "            \"Losses/val_loss\": self.val_losses[-1],\n",
    "            \"Accuracies/val_acc\": self.val_accs[-1],\n",
    "        }\n",
    "        self.wandb_run.log(wandb_dict)\n",
    "\n",
    "\n",
    "\n",
    "class BertTrainer_ft:\n",
    "    def __init__(self, model, train_set, val_set, epochs, batch_size, lr, device, stop_patience, wandb_mode, project_name, wandb_name):\n",
    "        \n",
    "        self.model = model\n",
    "        self.train_set = train_set\n",
    "        self.train_size = len(train_set)\n",
    "        self.val_set = val_set\n",
    "        self.epochs = epochs    \n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = self.train_size // self.batch_size\n",
    "        self.lr = lr\n",
    "        self.weight_decay = 0.01\n",
    "        self.current_epoch  = 0\n",
    "        self.early_stopping_counter = 0\t\n",
    "        self.patience = stop_patience\n",
    "        \n",
    "        \n",
    "        self.wandb_mode = wandb_mode\n",
    "        self.project_name = project_name\n",
    "        self.wandb_name = wandb_name\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index = -1).to(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def __call__(self):   \n",
    "        if self.wandb_mode:\n",
    "            self._init_wandb()   \n",
    "        self.val_set.prepare_dataset() \n",
    "        self.val_loader = DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False)\n",
    "        start_time = time.time()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self._init_result_lists()\n",
    "        for self.current_epoch in range(self.current_epoch, self.epochs):\n",
    "            #Training\n",
    "            self.model.train()\n",
    "            self.train_set.prepare_dataset()\n",
    "            self.train_loader = DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
    "            epoch_start_time = time.time()\n",
    "            avg_epoch_loss = self.train(self.current_epoch)\n",
    "            self.train_losses.append(avg_epoch_loss) \n",
    "            print(f\"Epoch completed in {(time.time() - epoch_start_time)/60:.1f} min\")\n",
    "            \n",
    "            #Validation\n",
    "            print(\"Evaluating on validation set...\")\n",
    "            val_results = self.evaluate(self.val_loader)\n",
    "            print(f\"Elapsed time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))}\")\n",
    "            self.val_losses.append(val_results[0])  \n",
    "            self.val_accs.append(val_results[1])\n",
    "            if self.wandb_mode:\n",
    "                self._report_epoch_results()\n",
    "            self._report_epoch_results()\n",
    "            criterion = self.stop_early()\n",
    "            if criterion:\n",
    "                print(f\"Training interrupted at epoch: {self.current_epoch+1}\")\n",
    "                break\n",
    "\n",
    "        print(f\"-=Training completed=-\")\n",
    "        results = {\n",
    "            \"best_epoch\": self.current_epoch,\n",
    "            \"train_losses\": self.train_losses,\n",
    "            \"val_losses\": self.val_losses,\n",
    "            \"val_accs\": self.val_accs\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    def _init_result_lists(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_accs = []\n",
    "    \n",
    "    def stop_early(self):\n",
    "        if self.val_losses[-1] < self.best_val_loss:\n",
    "            self.best_val_loss = self.val_losses[-1]\n",
    "            self.best_epoch = self.current_epoch\n",
    "            self.best_model_state = self.model.state_dict()\n",
    "            self.early_stopping_counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.early_stopping_counter += 1\n",
    "            return True if self.early_stopping_counter >= self.patience else False\n",
    "\n",
    "    def train(self, epoch: int):\n",
    "        print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "        time_ref = time.time()\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        reporting_loss = 0\n",
    "        printing_loss = 0\n",
    "        for i, batch in enumerate(self.train_loader):\n",
    "            input, token_target, attn_mask = batch\n",
    "            \n",
    "            self.optimizer.zero_grad() \n",
    "\n",
    "            tokens = self.model(input, attn_mask) \n",
    "            loss = self.criterion(tokens.transpose(-1, -2), token_target) \n",
    "            \n",
    "            epoch_loss += loss.item() \n",
    "            reporting_loss += loss.item()\n",
    "            printing_loss += loss.item()\n",
    "            \n",
    "            loss.backward() \n",
    "            self.optimizer.step()         \n",
    "        avg_epoch_loss = epoch_loss / self.num_batches\n",
    "        return avg_epoch_loss \n",
    "    \n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        total_correct = 0\n",
    "        total_tokens = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(loader):\n",
    "                input, token_target, attn_mask = batch\n",
    "                tokens = self.model(input, attn_mask)\n",
    "                loss = self.criterion(tokens.transpose(-1, -2), token_target)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                token_mask =  token_target != -1\n",
    "                predicted_tokens = tokens.argmax(dim=-1)\n",
    "                token_target = torch.masked_select(token_target, token_mask)\n",
    "                predicted_tokens = torch.masked_select(predicted_tokens, token_mask)\n",
    "                \n",
    "                correct = (predicted_tokens == token_target).sum().item()\n",
    "                total_correct += correct\n",
    "                total_tokens += token_target.numel() \n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(loader)\n",
    "        accuracy = total_correct / total_tokens\n",
    "\n",
    "        return avg_epoch_loss, accuracy\n",
    "    \n",
    "    def _save_model(self, savepath: Path):\n",
    "        torch.save(self.best_model_state, savepath)\n",
    "        print(f\"Model saved to {savepath}\")\n",
    "        \n",
    "        \n",
    "    def _load_model(self, savepath: Path):\n",
    "        print(f\"Loading model from {savepath}\")\n",
    "        self.model.load_state_dict(torch.load(savepath))\n",
    "        print(\"Model loaded\")\n",
    "\n",
    "    def _init_wandb(self):\n",
    "        self.wandb_run = wandb.init(\n",
    "            project=self.project_name, # name of the project\n",
    "            name=self.wandb_name, # name of the run\n",
    "            \n",
    "            config={\n",
    "                \"epochs\": self.epochs,\n",
    "                \"batch_size\": self.batch_size,\n",
    "                \"num_heads\": self.model.attention_heads,\n",
    "                \"num_encoders\": self.model.num_encoders,\n",
    "                \"emb_dim\": self.model.dim_inp,\n",
    "                'ff_dim': self.model.dim_out,\n",
    "                \"lr\": self.lr,\n",
    "                \"weight_decay\": self.weight_decay,\n",
    "                \"max_seq_len\": self.model.max_length[0],\n",
    "                \"vocab_size\": len(self.train_set.vocab),\n",
    "                \"num_parameters\": sum(p.numel() for p in self.model.parameters() if p.requires_grad),\n",
    "            }\n",
    "        )\n",
    "        self.wandb_run.watch(self.model) # watch the model for gradients and parameters\n",
    "        self.wandb_run.define_metric(\"epoch\", hidden=True)\n",
    "        self.wandb_run.define_metric(\"batch\", hidden=True)\n",
    "\n",
    "        self.wandb_run.define_metric(\"Losses/train_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        self.wandb_run.define_metric(\"Losses/val_loss\", summary=\"min\", step_metric=\"epoch\")\n",
    "        \n",
    "        self.wandb_run.define_metric(\"Losses/final_val_loss\")\n",
    "        self.wandb_run.define_metric(\"Accuracies/final_val_acc\")\n",
    "        self.wandb_run.define_metric(\"final_epoch\")\n",
    "\n",
    "        return self.wandb_run\n",
    "    \n",
    "    def _report_epoch_results(self):\n",
    "        wandb_dict = {\n",
    "            \"epoch\": self.current_epoch+1,\n",
    "            \"Losses/train_loss\": self.train_losses[-1],\n",
    "            \"Losses/val_loss\": self.val_losses[-1],\n",
    "            \"Accuracies/val_acc\": self.val_accs[-1],\n",
    "        }\n",
    "        self.wandb_run.log(wandb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, 1000 samples found\n",
      "length  of vocabulary: 1208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6acd82vc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd26e33968a74d24841fde3606e1961d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.015 MB uploaded\\r'), FloatProgress(value=0.059422213793539416, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test</strong> at: <a href='https://wandb.ai/strompfel/NCBI/runs/6acd82vc' target=\"_blank\">https://wandb.ai/strompfel/NCBI/runs/6acd82vc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240212_163013-6acd82vc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6acd82vc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0ad681bf1042a5b8ef185b01e30240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\erika\\Desktop\\Exjobb\\data\\wandb\\run-20240212_163246-r6tal2xq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/strompfel/NCBI/runs/r6tal2xq' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/strompfel/NCBI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/strompfel/NCBI' target=\"_blank\">https://wandb.ai/strompfel/NCBI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/strompfel/NCBI/runs/r6tal2xq' target=\"_blank\">https://wandb.ai/strompfel/NCBI/runs/r6tal2xq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:06\n",
      "Epoch 2/5\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:12\n",
      "Epoch 3/5\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:18\n",
      "Epoch 4/5\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:24\n",
      "Epoch 5/5\n",
      "Epoch completed in 0.1 min\n",
      "Evaluating on validation set...\n",
      "Elapsed time: 00:00:31\n",
      "-=Training completed=-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 4,\n",
       " 'train_losses': [6.716255130767823,\n",
       "  5.805294799804687,\n",
       "  5.029448509216309,\n",
       "  4.463122625350952,\n",
       "  4.1071098518371585],\n",
       " 'val_losses': [6.11516353062221,\n",
       "  5.36531925201416,\n",
       "  4.712193965911865,\n",
       "  4.294982944216047,\n",
       "  4.067011458533151],\n",
       " 'val_accs': [0.24260355029585798,\n",
       "  0.23668639053254437,\n",
       "  0.1893491124260355,\n",
       "  0.1952662721893491,\n",
       "  0.2485207100591716]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_builder import BERT\n",
    "from data_preprocessing import data_loader\n",
    "from build_vocabulary import make_vocabulary\n",
    "from misc import get_split_indices\n",
    "from create_dataset import NCBIDataset\n",
    "\n",
    "include_pheno = False\n",
    "\n",
    "NCBI = data_loader(include_pheno,threshold_year,path)\n",
    "vocabulary = make_vocabulary(NCBI, include_pheno)\n",
    "reduced_samples = 1000\n",
    "NCBI = NCBI.head(reduced_samples)\n",
    "print(f\"Data loaded, {len(NCBI)} samples found\")\n",
    "print(f\"length  of vocabulary:\",len(vocabulary))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_indices, val_indices = get_split_indices(len(NCBI), 0.2)\n",
    "train_set = NCBIDataset(NCBI.iloc[train_indices], vocabulary, max_length, mask_prob,include_pheno)\n",
    "val_set = NCBIDataset(NCBI.iloc[val_indices], vocabulary, max_length, mask_prob,include_pheno)\n",
    "\n",
    "bert_test = BERT(len(vocabulary), max_length, enc_dim_inp, enc_dim_out, attention_heads, num_encoders, drop_prob)\n",
    "\n",
    "test = BertTrainer(bert_test, train_set, val_set, epochs, batch_size, lr, device, stop_patience, True, \"NCBI\", \"test\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
