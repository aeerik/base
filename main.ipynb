{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "\n",
      " Retrieving data from: c:\\Users\\erika\\Desktop\\Exjobb\\data\n",
      "Loading data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Retrieving data from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m NCBI \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_pheno\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthreshold_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData correctly loaded, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(NCBI)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating vocabulary...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\erika\\Desktop\\Exjobb\\repo\\base\\data_preprocessing.py:32\u001b[0m, in \u001b[0;36mdata_loader\u001b[1;34m(include_pheno, threshold_year, path)\u001b[0m\n\u001b[0;32m     30\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=PARTIAL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=MISTRANSLATION\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=HMM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=PARTIAL_END_OF_CONTIG\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     31\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mNCBI\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [g \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m g\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;28mtuple\u001b[39m(labels))]) \n\u001b[0;32m     34\u001b[0m NCBI \u001b[38;5;241m=\u001b[39m NCBI[NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)] \n",
      "File \u001b[1;32mc:\\Users\\erika\\anaconda3\\envs\\dml\\lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erika\\anaconda3\\envs\\dml\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erika\\anaconda3\\envs\\dml\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\erika\\anaconda3\\envs\\dml\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\erika\\Desktop\\Exjobb\\repo\\base\\data_preprocessing.py:32\u001b[0m, in \u001b[0;36mdata_loader.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     30\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=PARTIAL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=MISTRANSLATION\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=HMM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=PARTIAL_END_OF_CONTIG\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     31\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([g\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m x])))\n\u001b[0;32m     33\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [g \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m g\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;28mtuple\u001b[39m(labels))]) \n\u001b[0;32m     34\u001b[0m NCBI \u001b[38;5;241m=\u001b[39m NCBI[NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)] \n",
      "File \u001b[1;32mc:\\Users\\erika\\Desktop\\Exjobb\\repo\\base\\data_preprocessing.py:32\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=PARTIAL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=MISTRANSLATION\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=HMM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=PARTIAL_END_OF_CONTIG\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     31\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([g\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m x])))\n\u001b[0;32m     33\u001b[0m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [g \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m g\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;28mtuple\u001b[39m(labels))]) \n\u001b[0;32m     34\u001b[0m NCBI \u001b[38;5;241m=\u001b[39m NCBI[NCBI[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)] \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Relevant packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchtext\n",
    "import torchtext.vocab as vocab\n",
    "import os\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "from misc import get_split_indices\n",
    "from misc import export_results\n",
    "from data_preprocessing import data_loader\n",
    "from build_vocabulary import make_vocabulary\n",
    "from create_dataset import NCBIDataset\n",
    "from bert_builder import BERT\n",
    "from trainer import BertTrainer\n",
    "\n",
    "#Data directory\n",
    "#Lokalt\n",
    "local_data_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\data'\n",
    "#saga\n",
    "saga_data_dir = \"/home/aeerik/data/raw/\"\n",
    "\n",
    "#save directory\n",
    "save_directory = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\savefiles'\n",
    "\n",
    "#System information\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Hyperparameters\n",
    "include_pheno = False\n",
    "threshold_year = 1970\n",
    "data_path = local_data_dir #ÄNDRA DENNA\n",
    "max_length = 51\n",
    "mask_prob = 0.15\n",
    "embedding_dim = 32\n",
    "drop_prob = 0.2\n",
    "limit_data = True\n",
    "reduced_samples = 1000 #Ta bort denna senare\n",
    "\n",
    "enc_dim_inp = 32 \n",
    "enc_dim_out = 32 \n",
    "attention_heads = 8 \n",
    "\n",
    "num_encoders = 4\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "stop_patience = 10\n",
    "export_model = True\n",
    "\n",
    "####################################################\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Using CPU\")  \n",
    "    \n",
    "print(f\"\\n Retrieving data from: {data_path}\")\n",
    "print(\"Loading data...\")\n",
    "NCBI = data_loader(include_pheno,threshold_year,data_path)\n",
    "print(f\"Data correctly loaded, {len(NCBI)} samples found\")\n",
    "\n",
    "print(\"Creating vocabulary...\")\n",
    "vocabulary = make_vocabulary(NCBI)\n",
    "print(f\"Vocabulary created with number of elements:\",len(vocabulary))\n",
    "\n",
    "if limit_data:\n",
    "    print(f\"Reducing samples to {reduced_samples}\")\n",
    "    NCBI = NCBI.head(reduced_samples)\n",
    "\n",
    "if include_pheno:\n",
    "    max_length = 51+37\n",
    "else:\n",
    "    max_length = 51\n",
    "\n",
    "train_indices, val_indices = get_split_indices(len(NCBI), 0.2)\n",
    "train_set = NCBIDataset(NCBI.iloc[train_indices], vocabulary, max_length, mask_prob)\n",
    "val_set = NCBIDataset(NCBI.iloc[val_indices], vocabulary, max_length, mask_prob)\n",
    "print(f\"Datasets has been created with {len(train_set)} samples in the training set and {len(val_set)} samples in the validation set\")\n",
    "\n",
    "print(f\"Creating model...\")\n",
    "model = BERT(len(vocabulary), max_length, enc_dim_inp, enc_dim_out, attention_heads, num_encoders, drop_prob)\n",
    "print(f\"Model successfully loaded\")\n",
    "print(f\"---------------------------------------------------------\")\n",
    "print(f\"Starting training...\")\n",
    "trainer = BertTrainer(model, train_set, val_set, epochs, batch_size, lr, device, stop_patience, save_directory)\n",
    "results = trainer()\n",
    "print(f\"---------------------------------------------------------\")\n",
    "if export_model:\n",
    "    print(f\"Exporting model...\")\n",
    "    export_model_label = str(today)+\"model.pkl\"\n",
    "    trainer._save_model(save_directory+\"/\"+export_model_label)\n",
    "print(\"Exporting results...\")\n",
    "export_results_label = str(today)+\"run.pkl\"\n",
    "export_results(results, save_directory+\"/\"+export_results_label)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
