{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relevant packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchtext\n",
    "import torchtext.vocab as vocab\n",
    "\n",
    "from misc import get_split_indices\n",
    "from data_preprocessing import data_loader\n",
    "from build_vocabulary import make_vocabulary\n",
    "from create_dataset import NCBIDataset\n",
    "from embedding import JointEmbedding\n",
    "from bert_builder import BERT\n",
    "\n",
    "#Data directory\n",
    "#Lokalt\n",
    "local_data_dir = 'c:\\\\Users\\\\erika\\\\Desktop\\\\Exjobb\\\\data'\n",
    "#saga\n",
    "saga_data_dir = \"/home/aeerik/data/raw/\"\n",
    "\n",
    "#Hyperparameters\n",
    "include_pheno = False\n",
    "threshold_year = 1970\n",
    "data_path = local_data_dir #Ã„NDRA DENNA\n",
    "max_length = 51\n",
    "mask_prob = 0.15\n",
    "embedding_dim = 32\n",
    "drop_prob = 0.2\n",
    "\n",
    "enc_dim_inp = 32 \n",
    "enc_dim_out = 32 \n",
    "attention_heads = 8 \n",
    "\n",
    "num_encoders = 2\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "stop_patience = 10\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
